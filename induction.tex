\chapter{归纳 (Induction)}
\label{cha:induction}

在 \cref{cha:typetheory} 中，我们介绍了许多从旧类型生成新类型的方法。
除了（依赖）函数类型和宇宙 (universe) 类型外，所有这些规则都是一般性概念“归纳定义 (inductive definition)”的特例。\index{definition!inductive}\index{inductive!definition}
在本章中，我们将更广泛地研究归纳定义。

\section{归纳类型简介 (Introduction to inductive types)}
\label{sec:bool-nat}

\index{type!inductive|(}%
\index{generation!of a type, inductive|(}
一种 \emph{归纳类型 (inductive type)} $X$ 可以直观地理解为由某个有限集合的 \emph{构造器 (constructors)} 自由生成的类型，这些构造器中的每一个都是一个以 $X$ 为目标域的函数（具有一定数量的参数）。
这包括零参数的函数，它们只是 $X$ 的元素。

在描述特定的归纳类型时，我们用项目符号列出构造器。
例如，来自 \cref{sec:type-booleans} 的类型 \bool 是由以下构造器归纳生成的：
\begin{itemize}
    \item $\bfalse:\bool$
    \item $\btrue:\bool$
\end{itemize}
类似地，$\unit$ 是由以下构造器归纳生成的：
\begin{itemize}
    \item $\ttt:\unit$
\end{itemize}
而 $\emptyt$ 则没有任何构造器。
一个构造器函数接受参数的示例是余积 (coproduct) $A+B$，它由以下两个构造器生成：
\begin{itemize}
    \item $\inl:A\to A+B$
    \item $\inr:B\to A+B$。
\end{itemize}
另一个接受多个参数的示例是笛卡尔积 (cartesian product) $A\times B$，它由以下构造器生成：
\begin{itemize}
    \item $\pairr{\blank, \blank} : A\to B \to A\times B$。
\end{itemize}
重要的是，我们还允许定义的归纳类型的构造器接受来自被定义的归纳类型的参数。
例如，自然数类型 (natural numbers) $\nat$ 的构造器为：
\begin{itemize}
    \item $0:\nat$
    \item $\suc:\nat\to\nat$。
\end{itemize}
\symlabel{lst}
\index{type!of lists}%
\indexsee{list}{type of lists}%
另一个有用的例子是类型 $\lst A$，它表示某个类型 $A$ 的有限列表，其构造器为：
\begin{itemize}\label{list_constructors}
\item $\nil:\lst A$
\item $\cons:A\to \lst A \to \lst A$。
\end{itemize}

\index{free!generation of an inductive type}%
直观上，我们应该将归纳类型理解为由其构造器 \emph{自由生成的} 类型。
即，归纳类型的元素正是通过从无到有并反复应用构造器获得的。
（我们将在 \cref{sec:identity-systems,cha:hits} 中看到，这种概念在处理更一般的归纳定义时需要略微修改，但现在我们这样理解是足够的。）
例如，对于 \bool，我们应该期望唯一的元素是 $\bfalse$ 和 $\btrue$。
类似地，对于 $\nat$，我们应该期望每个元素要么是 $0$，要么是通过对某个“先前构造的”自然数应用 $\suc$ 获得的。

\index{induction principle}%
然而，我们不是直接断言这样的性质，而是通过 \emph{归纳原理 (induction principle)}，也称为 \emph{（依赖）消去规则 (dependent elimination rule)} 来表达这些性质。
我们已经在 \cref{cha:typetheory} 中见过这些原理。
例如，\bool 的归纳原理是：
%
\begin{itemize}
    \item 在证明关于 \bool 的 \emph{所有} 居民的陈述 $E : \bool \to \type$ 时，只需要证明其对于 $\bfalse$ 和 $\btrue$ 成立，即给出证明 $e_0 : E(\bfalse)$ 和 $e_1 : E(\btrue)$。
\end{itemize}

此外，当应用于构造器 $\bfalse$ 和 $\btrue$ 时，所得证明 $\ind\bool(E,e_0,e_1): \prd{b : \bool}E(b)$ 的行为符合预期；这一原理通过 \emph{计算规则 (computation rules)} 表达：\index{computation rule!for type of booleans}：
\begin{itemize}
    \item 我们有 $\ind\bool(E,e_0,e_1,\bfalse) \jdeq e_0$。
    \item 我们有 $\ind\bool(E,e_0,e_1,\btrue) \jdeq e_1$。
\end{itemize}

\index{case analysis}%
因此，布尔类型 (type \bool) 的归纳原理允许我们通过 \emph{情况分析 (case analysis)} 进行推理。
由于这两个构造器都不接受任何参数，因此这是布尔类型所需的全部内容。

\index{natural numbers}%
然而，对于自然数，情况分析通常是不够的：在对应于归纳步骤 $\suc(n)$ 的情况下，我们还希望假定要证明的命题已经对 $n$ 成立。
这给出了以下归纳原理：
\begin{itemize}
    \item 在证明关于 \emph{所有} 自然数的命题 $E : \nat \to \type$ 时，只需证明其对 $0$ 和 $\suc(n)$ 成立，并假设其对 $n$ 成立，即构造 $e_z : E(0)$ 和 $e_s : \prd{n : \nat} E(n) \to E(\suc(n))$。
\end{itemize}
与布尔类型的情况类似，我们也有与函数 $\ind\nat(E,e_z,e_s) : \prd{x:\nat} E(x)$ 相关的计算规则：
\index{computation rule!for natural numbers}%
\begin{itemize}
    \item $\ind\nat(E,e_z,e_s,0) \jdeq e_z$。
    \item $\ind\nat(E,e_z,e_s,\suc(n)) \jdeq e_s(n,\ind\nat(E,e_z,e_s,n))$ 对于任意 $n : \nat$。
\end{itemize}
因此，依赖函数 $\ind\nat(E,e_z,e_s)$ 可以理解为在参数 $x : \nat$ 上递归定义，通过我们称为 \define{递归 (recurrences)}\indexdef{recurrence} 的函数 $e_z$ 和 $e_s$。
当 $x$ 为零时，函数仅返回 $e_z$。
当 $x$ 是另一个自然数 $n$ 的后继时，结果是通过取递归 $e_s$ 并替换特定的前任 $n$ 以及递归调用值 $\ind\nat(E,e_z,e_s,n)$ 来获得的。

上述所有示例的归纳原理都具有这种家族相似性。
在 \cref{sec:strictly-positive} 中，我们将讨论“归纳定义”的一般概念以及如何为其推导出适当的 \emph{归纳原理 (induction principle)}，但首先我们将探讨归纳定义之间的各种共性。

\index{recursion principle}%
例如，我们在 \cref{cha:typetheory} 的每个示例中都提到，通过归纳原理我们可以推导出 \emph{递归原理 (recursion principle)}，其中目标域是简单类型（而非族）。
虽然归纳和递归原理可能看起来很奇怪，因为它们仅仅产生了一个函数的 \emph{存在性}，而似乎没有唯一地描述它。
然而，事实上，归纳原理足够强大，可以证明其自身的 \emph{唯一性原理 (uniqueness principle)}\index{uniqueness!principle, propositional!for functions on N@for functions on $\nat$}，如下定理所示。

\begin{thm}\label{thm:nat-uniq}
设 $f,g : \prd{x:\nat} E(x)$ 为两个函数，它们满足以下递归关系
%
\begin{equation*}
    e_z : E(0)
    \qquad\text{和}\qquad
    e_s : \prd{n : \nat} E(n) \to E(\suc(n))
\end{equation*}
%
并且满足命题等价，即
\begin{equation*}
    \id{f(0)}{e_z}
    \qquad\text{和}\qquad
    \id{g(0)}{e_z}
\end{equation*}
以及
\begin{gather*}
    \prd{n : \nat} \id{f(\suc(n))}{e_s(n, f(n))},\\
    \prd{n : \nat} \id{g(\suc(n))}{e_s(n, g(n))}。
\end{gather*}
那么 $f$ 和 $g$ 是相等的。
\end{thm}

\begin{proof}
    我们对类型族 $D(x) \defeq \id{f(x)}{g(x)}$ 使用归纳法。对于基础情况，我们有
    \[ f(0) = e_z = g(0) \]。
    对于归纳情况，假设 $n : \nat$，使得 $f(n) = g(n)$。然后
    \[ f(\suc(n)) = e_s(n, f(n)) = e_s(n, g(n)) = g(\suc(n)) \]。
    第一个和最后一个等式来自于对 $f$ 和 $g$ 的假设。中间等式来自于归纳假设以及应用保持等式的事实。这给出了 $f$ 和 $g$ 之间的逐点等价；调用函数扩展性 (function extensionality) 完成证明。
\end{proof}

请注意，唯一性原理甚至适用于仅在命题等价下满足递归关系的函数，即路径。
当然，从归纳原理得到的特定函数在判断上 (judgmentally)\index{judgmental equality} 满足这些递归关系；我们将在 \cref{sec:htpy-inductive} 中回到这一点。
另一方面，该定理本身仅断言函数之间的命题等价（另见 \cref{ex:same-recurrence-not-defeq}）。
从同伦 (homotopical) 视角来看，询问这个路径是否 \emph{一致}，即 $f=g$ 的等价是否唯一存在是自然的；我们将在 \cref{sec:initial-alg} 中看到这确实是事实。

当然，类似的函数唯一性定理通常也可以为其他归纳类型表述和证明。
在下一节中，我们将展示这一唯一性性质与同一性 (univalence) 结合如何表明，像自然数这样的归纳类型完全由其引入、消去和计算规则表征。

\index{type!inductive|)}%
\index{generation!of a type, inductive|)}%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{归纳类型的唯一性 (Uniqueness of inductive types)}
\label{sec:appetizer-univalence}

\index{uniqueness!of identity types}%
我们已经定义了“自然数 (natural numbers)”作为一个特定类型 \nat，它具有特定的归纳生成器 $0$ 和 $\suc$。
然而，根据上一节中描述的类型论中归纳定义的一般原则，并没有什么阻止我们以相同的方式定义 \emph{另一个} 类型。
\index{natural numbers!isomorphic definition of}
也就是说，假设我们定义 $\natp$ 为由以下构造器生成的归纳类型：
\begin{itemize}
    \item $\zerop:\natp$
    \item $\sucp:\natp\to\natp$。
\end{itemize}
那么 $\natp$ 将具有与 \nat 相同的归纳和递归原理。
在证明关于所有这些“新”自然数的命题 $E : \natp \to \type$ 时，只需给出证明 $e_z : E(\zerop)$ 和 \narrowequation{e_s : \prd{n : \natp} E(n) \to E(\sucp(n))}。
函数 $\rec\natp(E,e_z,e_s) : \prd{n:\natp} E(n)$ 的计算规则如下：
\begin{itemize}
    \item $\rec\natp(E,e_z,e_s,\zerop) \jdeq e_z$，
    \item $\rec\natp(E,e_z,e_s,\sucp(n)) \jdeq e_s(n,\rec\natp(E,e_z,e_s,n))$ 对于任意 $n : \natp$。
\end{itemize}
但是 \nat 和 \natp 之间的关系是什么？

这不仅仅是一个学术问题，因为类似于自然数的结构可以在许多其他地方找到。
\index{type!of lists}%
例如，我们可以将自然数与具有一个元素的类型上的列表相对应（这是可以说的最早出现的形式，发现于洞穴墙壁上\index{caves, walls of}），与非负整数 (non-negative integers)、有理数 (rationals) 和实数 (reals) 的子集相对应，等等。
从编程\index{programming} 的角度来看，我们的自然数的“一元 (unary)”表示是非常低效的，因此有时我们可能更喜欢使用二进制表示。
我们希望能够将所有这些版本的“自然数”彼此识别，以便在它们之间传递构造和结果。

当然，如果两个版本的自然数满足相同的归纳原理，那么它们将具有相同的诱导结构。
例如，回想在 \cref{sec:inductive-types} 中定义的函数 $\dbl$ 的例子。对于我们的新自然数，可以通过复制并添加引号来轻松定义类似的函数：
\[ \dblp \defeq \rec\natp(\natp, \; \zerop, \;  \lamu{n:\natp}{m:\natp} \sucp(\sucp(m)))。 \]
看似简单，但它带来了显而易见的缺点，即导致大量重复。不仅函数必须被重复，所有引理和它们的证明也必须被“加引号”。

在传统数学中，人们只是宣布 \nat 和 \natp 显然是“相同的”，并且可以根据需要将它们互换。
这通常没有问题，但它掩盖了相当多的细节，扩大了非正式数学与其精确描述之间的差距。
在同伦类型论 (homotopy type theory) 中，我们可以做得更好。

首先观察我们可以定义以下映射：
\begin{itemize}
    \item $f \defeq \rec\nat(\natp, \; \zerop, \;  \lamu{n:\nat} \sucp) : \nat \to\natp$，
    \item $g \defeq \rec\natp(\nat, \; 0, \;  \lamu{n:\natp} \suc) : \natp \to\nat$。
\end{itemize}
由于 $g$ 和 $f$ 的复合满足与 $\nat$ 上的恒等函数相同的递归关系，\cref{thm:nat-uniq} 得出 $\prd{n : \nat} \id{g(f(n))}{n}$，而同一定理的“加引号”版本得出 $\prd{n : \natp} \id{f(g(n))}{n}$。
因此，$f$ 和 $g$ 是准逆 (quasi-inverses)，因此 $\eqv{\nat}{\natp}$。
我们现在可以沿着这个等价将 \nat 上的函数直接转移到 \natp 上（反之亦然），例如
\[ \dblp \defeq \lamu{n:\natp} f(\dbl(g(n)))。 \]
不难证明这个版本的 $\dblp$ 与前一个版本相等。

当然，这并不令人惊讶；这种同构正是数学家在设想“识别” $\nat$ 与 $\natp$ 时的方式。
然而，“通过同构转移 (transfer across an isomorphism)”的机制取决于被转移的对象；它并不总是像将单个函数与 $f$ 和 $g$ 预先和后续组合那样简单。
考虑例如一个简单的引理：
\[\prd{n : \natp} \dblp(\sucp(n))=\sucp(\sucp(\dblp(n)))。\]
插入正确的 $f$s 和 $g$s 仅仅比直接在 $n:\natp$ 上重新证明它稍微容易一点。
\index{isomorphism!transfer across}%

\index{univalence axiom}%
在此处，同一性公理 (univalence axiom) 发挥作用：由于 $\eqv{\nat}{\natp}$，我们还具有 $\id[\type]{\nat}{\natp}$，即 \nat 和 \natp 作为类型是 \emph{相等的}。
现在，身份 (identity) 的归纳原理保证了与 \nat 相关的任何构造或证明都可以自动转移到 \natp 上。
我们只需将函数或定理的类型视为一个以类型为索引的类型族 $P:\type\to\type$，给定的对象是 $P(\nat)$ 的一个元素，并沿着路径 $\id \nat\natp$ 传输即可。
这涉及的开销要少得多。

为了简单起见，我们在两个具有 \emph{相同} 定义的类型 \nat 和 \natp 的情况下描述了这种方法。
然而，在实践中更常见的情况是定义并不完全相同，但无论如何，一个归纳原理蕴涵了另一个。
\index{type!unit}%
\index{natural numbers!encoded as list(unit)@encoded as $\lst\unit$}%
例如，考虑从一个单元素类型构造的列表类型 $\lst\unit$，它由以下内容生成：
\begin{itemize}
    \item 一个元素 $\nil:\lst\unit$，以及
    \item 一个函数 $\cons:\unit \times \lst\unit \to\lst\unit$。
\end{itemize}
这与 \nat 的定义不同，它并没有产生相同的归纳原理。
$\lst\unit$ 的归纳原理表明，对于任意 $E:\lst\unit\to\type$ 及其递归数据 $e_\nil:E(\nil)$ 和 $e_\cons : \prd{u:\unit}{\ell:\lst\unit} E(\ell) \to E(\cons(u,\ell))$，存在 $f:\prd{\ell:\lst\unit} E(\ell)$，使得 $f(\nil)\jdeq e_\nil$ 且 $f(\cons(u,\ell))\jdeq e_\cons(u,\ell,f(\ell))$。
（我们将在 \cref{sec:strictly-positive} 中看到如何推导归纳定义的归纳原理。）

现在假设我们定义 $0'' \defeq \nil: \lst\unit$，并通过 $\suc''(\ell) \defeq \cons(\ttt,\ell)$ 定义 $\suc'':\lst\unit\to\lst\unit$。
那么，对于任意 $E:\lst\unit\to\type$ 及其 $e_0:E(0'')$ 和 $e_s:\prd{\ell:\lst\unit} E(\ell) \to E(\suc''(\ell))$，我们可以定义
\begin{align*}
    e_\nil &\defeq e_0\\
    e_\cons(\ttt,\ell,x) &\defeq e_s(\ell,x)。
\end{align*}
（在 $e_\cons$ 的定义中，我们使用 $\unit$ 的归纳原理假设 $u$ 是 $\ttt$。）
现在我们可以应用 $\lst\unit$ 的归纳原理，得到 $f:\prd{\ell:\lst\unit} E(\ell)$，使得
\begin{gather*}
    f(0'') \jdeq f(\nil) \jdeq e_\nil \jdeq e_0\\
    f(\suc''(\ell)) \jdeq f(\cons(\ttt,\ell)) \jdeq e_\cons(\ttt,\ell,f(\ell)) \jdeq e_s(\ell,f(\ell))。
\end{gather*}
因此，$\lst\unit$ 满足与 \nat 相同的归纳原理，因此（根据上述相同的论证）与其相等。

最后，这些结论并不局限于自然数：它们适用于任何归纳类型。
如果我们有一个归纳定义的类型 $W$，以及另一个类型 $W'$，它满足与 $W$ 相同的归纳原理，那么可以推断出 $\eqv{W}{W'}$，因此 $W=W'$。
我们使用为 $W$ 和 $W'$ 推导出的递归原理构造映射 $W\to W'$ 和 $W'\to W$，然后使用每个的归纳原理证明两个复合等于恒等映射。
例如，在 \cref{cha:typetheory} 中，我们看到可以将 $A+B$ 的并 (coproduct) 也定义为 $\sm{x:\bool} \rec{\bool}(\UU,A,B,x)$。
后者的类型满足与前者相同的归纳原理；因此它们是规范等价的。

这当然与范畴论 (category theory) 中的熟悉事实非常相似，即如果两个对象具有相同的 \emph{泛性质 (universal property)}，那么它们是等价的。
在 \cref{sec:initial-alg} 中我们将看到归纳类型实际上具有一个泛性质，因此这是该一般原则的表现形式。
\index{universal property}


\section{\texorpdfstring{$\w$}{W}-类型 ($\w$-types)}
\label{sec:w-types}

归纳类型非常广泛，这对于它们的实用性和适用性来说是极好的，但使它们整体上难以研究。
幸运的是，它们都可以形式化地简化为几个特殊情况。
本书的范围之外不会讨论这种简化——这对在实践中使用类型论的数学家来说也无关紧要——但我们将花一些时间讨论我们尚未遇到的基本特殊情况之一。
这些是 Martin-Löf 的 \emph{$\w$-类型}，也称为 \emph{良基树 (well-founded trees)} 类型。
\index{tree, well-founded}%
$\w$-类型是自然数、列表和二叉树等类型的推广，它们足够通用，能够封装 \emph{任何} 归纳类型的“递归”方面。

一个特定的 $\w$-类型由给定的两个参数 $A : \type$ 和 $B : A \to \type$ 指定，在这种情况下，得到的 $\w$-类型写作 $\wtype{a:A} B(a)$。
类型 $A$ 表示 $\wtype{a :A} B(a)$ 的 \emph{标签 (labels)} 类型，它们作为构造器 (constructors)（然而，我们保留这个词用于归纳定义中出现的实际函数）。例如，在将自然数定义为 $\w$-类型时，%
\index{natural numbers!encoded as a W-type@encoded as a $\w$-type}
类型 $A$ 是由两个元素 $\bfalse$ 和 $\btrue$ 组成的类型 $\bool$，因为获得自然数的方式恰好有两种——它将是 $0$ 或者是另一个自然数的继承者。

类型族 $B : A \to \type$ 用于记录标签的元数 (arity)：一个标签 $a : A$ 将采用一个以 $B(a)$ 为索引的归纳参数族。我们可以因此将其理解为“$B(a)$-多个”标签的参数。这些参数由一个函数 $f : B(a) \to \wtype{a :A} B(a)$ 表示，理解为对于任意 $b : B(a)$，$f(b)$ 是标签 $a$ 的第“$b$”个参数。因此，$\w$-类型 $\wtype{a :A} B(a)$ 可以被视为良基树的类型，其中节点由 $A$ 的元素标记，每个由 $a : A$ 标记的节点具有 $B(a)$-多个分支。

在自然数的情况下，标签 $\bfalse$ 具有 0 元数，因为它构造了常量 0\index{zero}；标签 $\btrue$ 具有 1 元数，因为它构造了其参数的继承者\index{successor}。我们可以通过对 $\bool$ 的简单消去定义一个函数 $\rec\bool(\bbU,\emptyt,\unit)$ 到类型宇宙；这个函数对于 $\bfalse$ 返回空类型 $\emptyt$，对于 $\btrue$ 返回单位类型 $\unit$。因此我们可以定义
\symlabel{natw}
\index{type!unit}%
\index{type!empty}%
\[ \natw \defeq \wtype{b:\bool} \rec\bool(\bbU,\emptyt,\unit,b) \]
其中上标 $\mathbf{w}$ 用于将这种自然数版本与之前使用的版本区分开来。
类似地，我们可以将类型 $A$ 上的列表\index{type!of lists} 定义为具有 $\unit + A$ 个标签的 $\w$-类型：一个用于空列表的零元标签，再加上每个 $a : A$ 的一个一元标签，对应于将 $a$ 添加到列表的头部：
\[ \lst A \defeq \wtype{x: \unit + A} \rec{\unit + A}(\bbU, \; \emptyt, \; \lamu{a:A} \unit,\; x) \]。
\index{W-type@$\w$-type}%
\indexsee{type!W-@$\w$-}{$\w$-type}%
一般来说，由 $A : \type$ 和 $B : A \to \type$ 指定的 $\w$-类型 $\wtype{x:A} B(x)$ 是由以下构造器生成的归纳类型：
\begin{itemize}
    \item \label{defn:supp}
    $\supp : \prd{a:A} \Big(B(a) \to \wtype{x:A} B(x)\Big) \to \wtype{x:A} B(x)$。
\end{itemize}
%
构造器 $\supp$（“上确界 (supremum)”的缩写\index{supremum!constructor of a W-type@constructor of a $\w$-type}）接受一个标签 $a : A$ 和一个函数 $f : B(a) \to \wtype{x:A} B(x)$，该函数表示标签 $a$ 的参数，并构造出 $\wtype{x:A} B(x)$ 的一个新元素。使用我们之前将自然数编码为 $\w$-类型的方法，我们可以例如定义
\begin{equation*}
    \zerow \defeq \supp(\bfalse, \; \lamu{x:\emptyt} \rec\emptyt(\natw,x))。
\end{equation*}
换句话说，我们使用标签 $\bfalse$ 来构造 $\zerow$。然后，$\rec\bool(\bbU,\emptyt,\unit, \bfalse)$ 计算为 $\emptyt$，正如它应该的那样，因为 $\bfalse$ 是一个零元标签。因此，我们需要构造一个函数 $f : \emptyt \to \natw$，该函数表示提供给 $\bfalse$ 的（零个）参数。这当然是微不足道的，使用对 $\emptyt$ 的简单消去就能实现。同样地，我们可以定义 $1^{\mathbf{w}}$ 和一个继承者函数 $\sucw$
\begin{align*}
    1^{\mathbf{w}} &\defeq \supp(\btrue, \; \lamu{x:\unit} 0^{\mathbf{w}}) \\
    \sucw&\defeq \lamu{n:\natw} \supp(\btrue, \; \lamu{x:\unit} n)。
\end{align*}

\index{induction principle!for W-types@for $\w$-types}%
我们有以下针对 $\w$-类型的归纳原理：
\begin{itemize}
    \item 在证明关于所有 $\w$-类型 $\wtype{x:A} B(x)$ 元素的命题 $E : \big(\wtype{x:A} B(x)\big) \to \type$ 时，只需证明对于 $\supp(a,f)$ 的情况即可，假设它对所有 $b : B(a)$ 的 $f(b)$ 都成立。
    换句话说，只需给出一个证明
    \begin{equation*}
        e : \prd{a:A}{f : B(a) \to \wtype{x:A} B(x)}{g : \prd{b : B(a)} E(f(b))} E(\supp(a,f))
    \end{equation*}
\end{itemize}

\index{variable}%
变量 $g$ 代表我们的归纳假设，即所有标签 $a$ 的参数都满足 $E$。为了陈述这一点，我们对所有类型 $B(a)$ 的元素进行量化，因为每个 $b : B(a)$ 对应于标签 $a$ 的一个参数 $f(b)$。

我们如何在编码为 $\w$-类型的自然数上定义函数 $\dbl$？我们希望使用 $\natw$ 的递归原理，其余元类型为 $\natw$ 本身。因此我们需要构造一个合适的函数
\[e : \prd{a : \bool}{f : B(a) \to \natw}{g : B(a) \to \natw} \natw\]
它将表示 $\dbl$ 函数的递归；为了简化，我们将类型族 $\rec\bool(\bbU,\emptyt,\unit)$ 表示为 $B$。

显然，$e$ 将是一个以 $a : \bool$ 为第一个参数的函数。下一步是对 $a$ 进行案例分析，并根据它是 $\bfalse$ 还是 $\btrue$ 进行处理。这表明以下形式的定义
\[ e \defeq \lamu{a:\bool} \ind\bool(C,e_0,e_1,a) \]
其中
\[C \defeq \lamu{a:\bool} \prd{f : B(a) \to \natw}{g : B(a) \to \natw} \natw。\]
如果 $a$ 是 $\bfalse$，则类型 $B(a)$ 变为 $\emptyt$。因此，给定 $f : \emptyt \to \natw$ 和 $g : \emptyt \to \natw$，我们想要构造 $\natw$ 的一个元素。由于标签 $\bfalse$ 表示 $\emptyt$，它需要零个归纳参数，变量 $f$ 和 $g$ 是无关紧要的。我们返回 $\zerow$\index{zero} 作为结果：
\[ e_0 \defeq \lamu{f:\emptyt \to \natw}{g:\emptyt \to \natw} \zerow。 \]
类似地，如果 $a$ 是 $\btrue$，则类型 $B(a)$ 变为 $\unit$。
由于标签 $\btrue$ 表示继承者\index{successor} 操作符，它需要一个归纳参数——前驱\index{predecessor}——由变量 $f : \unit \to \natw$ 表示。
对前驱的递归调用的值由变量 $g : \unit \to \natw$ 表示。
因此，取这个值（即 $g(\ttt)$）并将继承者函数应用两次即可得到所需的结果：
\begin{equation*}
    e_1 \defeq \; \lamu{f:\unit \to \natw}{g:\unit \to \natw} \sucw(\sucw(g(\ttt)))。
\end{equation*}
将这些结合在一起，我们有
\[ \dbl \defeq \rec\natw(\natw, e) \]
其中 $e$ 的定义如上。

\symlabel{defn:recursor-wtype}
函数 $\rec{\wtype{x:A} B(x)}(E,e) : \prd{w : \wtype{x:A} B(x)} E(w)$ 的关联计算规则如下。
\index{computation rule!for W-types@for $\w$-types}%
\begin{itemize}
    \item
    对于任意 $a : A$ 和 $f : B(a) \to \wtype{x:A} B(x)$，我们有
    \begin{equation*}
        \rec{\wtype{x:A} B(x)}(E,e,\supp(a,f)) \jdeq
        e(a,f,\big(\lamu{b:B(a)} \rec{\wtype{x:A} B(x)}(E,e,f(b))\big))。
    \end{equation*}
\end{itemize}
换句话说，函数 $\rec{\wtype{x:A} B(x)}(E,e)$ 满足递归 $e$。

根据上述计算规则，函数 $\dbl$ 表现如预期：
\begin{align*}
    \dbl(\zerow) & \jdeq \rec\natw(\natw, e, \supp(\bfalse, \; \lamu{x:\emptyt} \rec\emptyt(\natw,x))) \\
    & \jdeq e(\bfalse, \big(\lamu{x:\emptyt} \rec\emptyt(\natw,x)\big),
    \big(\lamu{x:\emptyt} \dbl(\rec\emptyt(\natw,x))\big)) \\
    & \jdeq e_0(\big(\lamu{x:\emptyt} \rec\emptyt(\natw,x)\big), \big(\lamu{x:\emptyt} \dbl(\rec\emptyt(\natw,x))\big))\\
    & \jdeq \zerow \\
    \intertext{并且}
    \dbl(1^{\mathbf{w}}) & \jdeq \rec\natw(\natw, e, \supp(\btrue, \; \lamu{x:\unit} \zerow)) \\
    & \jdeq e(\btrue, \big(\lamu{x:\unit} \zerow\big), \big(\lamu{x:\unit} \dbl(\zerow)\big)) \\
    & \jdeq e_1(\big(\lamu{x:\unit} \zerow\big), \big(\lamu{x:\unit} \dbl(\zerow)\big)) \\
    & \jdeq \sucw(\sucw\big((\lamu{x:\unit} \dbl(\zerow))(\ttt)\big))\\
    & \jdeq \sucw(\sucw(\zerow))
\end{align*}
等等。

就像自然数一样，我们可以证明 $\w$-类型的唯一性定理：
\begin{thm}\label{thm:w-uniq}
\index{uniqueness!principle, propositional!for functions on W-types@for functions on $\w$-types}%
设 $g,h : \prd{w:\wtype{x:A}B(x)} E(w)$ 是两个满足递归
%
\begin{equation*}
    e : \prd{a,f} \Parens{\prd{b : B(a)} E(f(b))} \to  E(\supp(a,f))，
\end{equation*}
%
命题的函数，即满足
%
\begin{gather*}
    \prd{a,f} \id{g(\supp(a,f))} {e(a,f,\lamu{b:B(a)} g(f(b)))}，\\
    \prd{a,f} \id{h(\supp(a,f))}{e(a,f,\lamu{b:B(a)} h(f(b)))}。
\end{gather*}
然后 $g$ 和 $h$ 是相等的。
\end{thm}


\section{归纳类型是初始代数 (Inductive types are initial algebras)}
\label{sec:initial-alg}

\indexsee{initial!algebra characterization of inductive types}{homotopy-initial}%

如前所述，归纳类型 (Inductive types) 也具有范畴论中的一种普遍性质。它们是\emph{同伦初始代数 (homotopy-initial algebras)}：在由特定构造子 (constructors) 决定的“代数 (algebras)”范畴中，同伦初始代数是初始对象（在一致同伦 (coherent homotopy) 范畴中）。举一个简单的例子，考虑自然数 (natural numbers)。这里适当的“代数”是一种类型，具有与 $\nat$ 的构造子所赋予的相同结构。

\index{natural numbers!as homotopy-initial algebra}
\begin{defn}\label{defn:nalg}
\define{$\nat$-代数 ($\nat$-algebra)}
\indexdef{N-algebra@$\nat$-algebra}%
\indexdef{algebra!N-@$\nat$-}%
是一种类型 $C$，具有两个元素 $c_0 : C$ 和 $c_s : C \to C$。这种代数的类型为：
\begin{equation*}
    \nalg \defeq \sm {C : \type} C \times (C \to C).
\end{equation*}
\end{defn}

\begin{defn}\label{defn:nhom}
\define{$\nat$-同态 ($\nat$-homomorphism)}
\indexdef{N-homomorphism@$\nat$-homomorphism}%
\indexdef{homomorphism!N-@$\nat$-}%
在 $\nat$-代数 $(C,c_0,c_s)$ 和 $(D,d_0,d_s)$ 之间的同态是一个函数 $h : C \to D$，使得对所有 $c : C$，都有 $h(c_0) = d_0$ 且 $h(c_s(c)) = d_s(h(c))$。这些同态的类型为：
\begin{narrowmultline*}
    \nhom((C,c_0,c_s),(D,d_0,d_s)) \defeq \narrowbreak
    \dsm {h : C \to D} (\id{h(c_0)}{d_0}) \times \tprd{c:C} (\id{h(c_s(c))}{d_s(h(c))}).
\end{narrowmultline*}
\end{defn}

因此，我们有一个 $\nat$-代数和 $\nat$-同态的范畴，$\nat$ 是这个范畴的初始对象。范畴论专家会立即认识到这就是范畴中自然数对象的定义。

当然，由于我们的类型表现得像 $\infty$-群体 ($\infty$-groupoids)\index{.infinity-groupoid@$\infty$-groupoid}，我们实际上有一个 $\nat$-代数的 $(\infty,1)$-范畴\index{.infinity1-category@$(\infty,1)$-category}，我们应当要求 $\nat$ 在合适的 $(\infty,1)$-范畴意义上是初始的。幸运的是，我们可以在不需要定义 $(\infty,1)$-范畴的情况下表述这一点。

\begin{defn}
    \index{universal!property!of natural numbers}%
    称 $\nat$-代数 $I$ 为\define{同伦初始 (homotopy-initial)}\indexdef{homotopy-initial!N-algebra@$\nat$-algebra}\indexdef{N-algebra@$\nat$-algebra!homotopy-initial (h-initial)}，简称 \define{h-initial}\indexsee{h-initial}{homotopy-initial}，如果对于任意其他的 $\nat$-代数 $C$，从 $I$ 到 $C$ 的 $\nat$-同态类型是可收缩的。即：
    \begin{equation*}
        \ishinitn(I) \defeq \prd{C : \nalg} \iscontr(\nhom(I,C)).
    \end{equation*}
\end{defn}

当它们存在时，同伦初始代数是唯一的——不仅仅是同构意义上的唯一，而是通过单值性公理 (univalence axiom) 来实现的等同。

\begin{thm}
    任何两个同伦初始的 $\nat$-代数是相等的。因此，同伦初始的 $\nat$-代数的类型是一个单命题 (mere proposition)。
\end{thm}
\begin{proof}
    假设 $I$ 和 $J$ 是同伦初始的 $\nat$-代数。那么 $\nhom(I,J)$ 是可收缩的，因此包含某个 $\nat$-同态 $f:I\to J$，同样我们有一个 $\nat$-同态 $g:J\to I$。现在，复合 $g\circ f$ 是从 $I$ 到 $I$ 的 $\nat$-同态，$\idfunc[I]$ 也是如此；但是 $\nhom(I,I)$ 是可收缩的，所以 $g\circ f = \idfunc[I]$。同样，$f\circ g = \idfunc[J]$。因此 $\eqv IJ$，也就是说 $I=J$。由于可收缩性是一个单命题，并且依赖乘积保留单命题，因此同伦初始也是一个单命题。因此，任何两个证明 $I$（或 $J$）是同伦初始的证明必然是相等的，从而完成了证明。
\end{proof}

现在我们有了以下定理。

\begin{thm}\label{thm:nat-hinitial}
$\nat$-代数 $(\nat, \emptyt, \suc)$ 是同伦初始的。
\end{thm}
\begin{proof}[证明概述]
    固定任意 $\nat$-代数 $(C,c_0,c_s)$。$\nat$ 的递归原理给出了一个函数 $f:\nat\to C$，定义如下：
    \begin{align*}
        f(0) &\defeq c_0\\
        f(\suc(n)) &\defeq c_s(f(n))。
    \end{align*}
    这两个等式使得 $f$ 成为一个 $\nat$-同态，我们可以将其作为 $\nhom(\nat,C)$ 的收缩中心。唯一性定理（见 \cref{thm:nat-uniq}）然后表明，任何其他的 $\nat$-同态都等于 $f$。
\end{proof}

为了将其置于更一般的背景下，考虑\emph{自函子 (endofunctor) 的代数}的概念。\index{algebra!for an endofunctor}注意，使一种类型 $C$ 成为 $\nat$-代数与给出一个函数 $c:C+\unit\to C$ 是等价的，并且一个函数 $f:C\to D$ 是 $\nat$-同态，当且仅当 $f \circ c \htpy d \circ (f+\unit)$。在范畴语言中，这意味着 $\nat$-代数是类型范畴中自函子 $F(X)\defeq X+1$ 的代数。

\indexsee{functor!polynomial}{endofunctor, polynomial}%
\indexsee{polynomial functor}{endofunctor, polynomial}%
\indexdef{endofunctor!polynomial}%
\index{W-type@$\w$-type!as homotopy-initial algebra}
对于更一般的情况，考虑与 $A : \type$ 和 $B : A \to \type$ 关联的 $\w$-类型 (W-types)。在这种情况下，我们有一个关联的\define{多项式函子 (polynomial functor)}：
\begin{equation}
    \label{eq:polyfunc}
    P(X) = \sm{x : A} (B(x) \rightarrow X)。
\end{equation}
实际上，这个赋值仅在同伦意义上是函子的，但这在接下来的讨论中没有影响。根据定义，\define{$P$-代数 ($P$-algebra)}\indexdef{algebra!for a polynomial functor}\indexdef{algebra!W-@$\w$-}是类型 $C$，配有一个函数 $s_C :  PC \rightarrow C$。根据 $\Sigma$-类型的通用性质，这相当于给出一个函数 $\prd{a:A} (B(a) \to C) \to C$。我们还将这种对象称为 \define{$\w$-代数 ($\w$-algebras)}\indexdef{W-algebra@$\w$-algebra}，我们记为
\symlabel{walg}
\begin{equation*}
    \walg(A,B) \defeq \sm {C : \type} \prd{a:A} (B(a) \to C) \to C。
\end{equation*}

类似地，对于 $P$-代数 $(C,s_C)$ 和 $(D,s_D)$，一个 \define{同态 (homomorphism)}\indexdef{homomorphism!of algebras for a functor}%
在它们之间的同态 $(f, s_f) : (C, s_C) \rightarrow (D, s_D)$ 由一个函数 $f : C \rightarrow D$ 和一个在 $PC \rightarrow D$ 之间的同伦构成
\[
    s_f :  f \circ s_C \, = s_{D} \circ Pf,
\]
其中 $Pf : PC\rightarrow PD$ 是 $P$ 在 $f: C \rightarrow D$ 上的可轻易定义的作用结果。这样的代数同态可以表示为：
\[
    \xymatrix{
        PC \ar[d]_{s_C} \ar[r]^{Pf}  \ar@{}[dr]|{s_f} &  PD \ar[d]^{s_D}\\
        C \ar[r]_{f}   & D }
\]
在元素的层面上，$f$ 是一个 $P$-同态 (或 \define{$\w$-同态 ($\w$-homomorphism)})\indexdef{W-homomorphism@$\w$-homomorphism}\indexdef{homomorphism!W-@$\w$-}%
若
\[f(s_C(a,h)) = s_D(a,f \circ h)。\]
我们有 $\w$-同态的类型：
\symlabel{whom}
\begin{equation*}
    \whom_{A,B}((C, s_C),(D,s_D)) \defeq \sm{f : C \to D} \prd{a:A}{h:B(a)\to C} \id{f(s_C(a,h))}{s_D(a, f\circ h)}
\end{equation*}

\index{universal!property!of $\w$-type}%
最后，一个 $P$-代数 $(C, s_C)$ 被称为\define{同伦初始 (homotopy-initial)}\indexdef{homotopy-initial!algebra for a functor}\indexdef{homotopy-initial!W-algebra@$\w$-algebra}%
如果对于每个 $P$-代数 $(D, s_D)$，从 $(C, s_C)$ 到 $(D, s_D)$ 的所有代数同态的类型是可收缩的。即：
\begin{equation*}
    \ishinitw(A,B,I) \defeq \prd{C : \walg(A,B)} \iscontr(\whom_{A,B}(I,C))。
\end{equation*}

现在与 \cref{thm:nat-hinitial} 类似的定理是：

\begin{thm}\label{thm:w-hinit}
对于任意类型 $A : \type$ 和类型族 $B : A \to \type$，$\w$-代数 $(\wtype{x:A}B(x), \supp)$ 是同伦初始的。
\end{thm}

\begin{proof}[证明概述]
    假设我们有 $A : \type$ 和 $B : A \to \type$，并考虑关联的多项式函子 $P(X)\defeq\sm{x:A}(B(x)\to X)$。令 $W \defeq \wtype{x:A}B(x)$。然后使用 \cref{sec:w-types} 中的 $\w$-引入规则，我们有一个结构映射 $s_W\defeq\supp: PW \rightarrow W$。我们要证明代数 $(W, s_W)$ 是同伦初始的。因此，让我们考虑另一个代数 $(C,s_C)$ 并证明 $\w$-同态从 $(W, s_W)$ 到 $(C, s_C)$ 的类型 $T\defeq \whom_{A,B}((W, s_W),(C,s_C)) $ 是可收缩的。为此，观察到 $\w$-消去规则和 $\w$-计算规则允许我们定义一个 $\w$-同态 $(f, s_f) : (W, s_W) \rightarrow (C, s_C)$，从而表明 $T$ 是可居住的。此外，有必要表明，对于每个 $\w$-同态 $(g, s_g) : (W, s_W) \rightarrow (C, s_C)$，存在一个等式证明
    \begin{equation}
        \label{equ:prequired}
        p :  (f,s_f) = (g,s_g)。
    \end{equation}
    这利用了一个事实，即一般来说，$(f,s_f) = (g,s_g) $ 形式的类型等价于我们所称的从 $f$ 到 $g$ 的 \define{代数 $2$-胞腔 (algebra $2$-cells)}\indexdef{algebra!2-cell}%
    的类型，其标准元素是 $(e, s_e)$ 形式的对，其中 $e : f=g$ 并且 $s_e$ 是在以下粘贴图所代表的等式证明之间的更高等式证明：
    \[
        \xymatrix{
            PW \ar@/^1pc/[r]^{Pg}   \ar[d]_{s_W}   \ar@/_1pc/[r]_{Pf} \ar@{}[r]|{Pe}
            & PC \ar[d]^{s_C}  \\
            W  \ar@/_1pc/[r]_f  \ar@{}[r]^{s_f} & C } \qquad
        \xymatrix{
            PW \ar@/^1pc/[r]^{Pg}   \ar[d]_{s_W} \ar@{}[r]_(.52){s_g}  & PC \ar[d]^{s_C}  \\
            W \ar@/^1pc/[r]^g  \ar@/_1pc/[r]_f  \ar@{}[r]|{e} & C }
    \]
    鉴于此事实，为证明存在 \eqref{equ:prequired} 中的元素，足以证明存在从 $f$ 到 $g$ 的代数 $2$-胞腔 $(e,s_e)$。等式证明 $e : f=g$ 现在通过函数扩展性和 $\w$-消去法则构造，以保证所需的等式证明 $s_e$ 的存在。
\end{proof}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{同伦归纳类型 (Homotopy-inductive types)}
\label{sec:htpy-inductive}

在 \cref{sec:w-types} 中，我们展示了如何将自然数 (natural numbers) 编码为 $\w$-类型 (W-types)，如下所示：
\begin{align*}
    \natw & \defeq \wtype{b:\bool} \rec\bool(\bbU,\emptyt,\unit,b), \\
    \zerow & \defeq \supp(\bfalse, (\lamu{x:\emptyt} \rec\emptyt(\natw,x))), \\
    \sucw & \defeq \lamu{n:\natw} \supp(\btrue, (\lamu{x:\unit} n))。
\end{align*}
我们还展示了如何使用递归原理 (recursion principle) 在 $\natw$ 上定义 $\dbl$ 函数。然而，当涉及到归纳原理 (induction principle) 时，这种编码不再令人满意：给定 $E : \natw \to \type$ 和递归 $e_z : E(\zerow)$ 以及 $e_s : \prd{n : \natw}  E(n) \to E(\sucw(n))$，我们只能构造出一个依赖函数 $r(E,e_z,e_s) : \prd{n : \natw} E(n)$，它仅在命题意义上（即通过路径）满足给定的递归。这意味着无法从 $\w$-类型的规则中显然推导出自然数的计算规则 (computation rules)，这些规则给出的是判断相等性 (judgmental equalities)。

\index{type!homotopy-inductive}%
\index{homotopy-inductive type}%
当我们考虑\emph{同伦归纳类型 (homotopy-inductive types)} 时，这个问题消失了。在同伦归纳类型中，所有的计算规则都是在路径意义上陈述的，即符号 $\jdeq$ 被替换为 $=$。例如，同伦版 $\w$-类型 $\mathsf{W^h}$ 的计算规则变为：
\index{computation rule!propositional}%
\begin{itemize}
    \item 对于任何 $a : A$ 和 $f : B(a) \to \wtypeh{x:A} B(x)$，我们有
    \begin{equation*}
        \rec{\wtypeh{x:A} B(x)}(E,e,\supp(a,f)) = e\Big(a,f,\big(\lamu{b:B(a)} \rec{\wtypeh{x:A} B(x)}(E,f(b))\big)\Big)
    \end{equation*}
\end{itemize}

同伦归纳类型在计算性质方面有一个显而易见的缺点——通过归纳原理构造的任何函数的行为现在只能通过命题性方式描述。但是，其他许多考虑因素也驱使我们考虑同伦归纳类型。例如，尽管我们在 \cref{sec:initial-alg} 中证明了归纳类型是同伦初始代数，但并非每个同伦初始代数都是归纳类型（即满足相应的归纳原理）——但每个同伦初始代数\emph{确实}是同伦归纳类型。类似地，当其中一个（或两个）涉及的类型仅是同伦归纳类型时，我们可能希望应用来自 \cref{sec:appetizer-univalence} 的唯一性论证——例如，证明 $\w$-类型编码的 $\nat$ 等价于通常的 $\nat$。

此外，同伦归纳类型的概念现在是类型论内部的。例如，这意味着我们可以形成所有自然数对象的类型并对其进行断言。在 $\w$-类型的情况下，我们可以将同伦 $\w$-类型 $\wtype{x:A} B(x)$ 表征为任何配有上确界 (supremum) 函数和满足适当（命题性）计算规则的归纳原理的类型：
\begin{multline*}
    \w_d(A,B) \defeq \sm{W : \type}
    \sm{\supp : \prd {a} (B(a) \to W) \to W}
    \prd{E : W \to \type} \\
    \prd{e : \prd{a,f} (\prd{b : B(a)} E(f(b))) \to E(\supp(a,f))}
    \sm{\ind{} : \prd{w : W} E(w)}
    \prd{a,f} \\
    \ind{}(\supp(a,f)) = e(a,\lamu{b:B(a)} \ind{}(f(b)))。
\end{multline*}
在 \cref{cha:hits} 中，我们将看到为什么命题性计算规则值得考虑的其他原因。

在本节中，我们将陈述一些关于同伦归纳类型的基本事实。我们省略了大部分证明，因为它们有些技术性。

\begin{thm}
    对于任何 $A : \type$ 和 $B : A \to \type$，类型 $\w_d(A,B)$ 是一个单命题。
\end{thm}

事实证明，存在 $\w$-类型的另一种等价表征，使用递归原理，加上某些\emph{唯一性 (uniqueness)}和\emph{一致性 (coherence)}法则。首先，我们给出递归原理：
%
\begin{itemize}
    \item 当从 $\w$-类型 $\wtypeh{x:A} B(x)$ 构造一个到类型 $C$ 的函数时，只需给出它在 $\supp(a,f)$ 处的值，假设我们已经给出所有 $f(b)$ 的值，其中 $b : B(a)$。换句话说，只需构造一个函数
    \begin{equation*}
        c : \prd{a:A} (B(a) \to C) \to C。
    \end{equation*}
\end{itemize}
\index{computation rule!propositional}%
与 $\rec{\wtypeh{x:A} B(x)}(C,c) : (\wtype{x:A} B(x)) \to C$ 关联的计算规则如下：
\begin{itemize}
    \item 对于任何 $a : A$ 和 $f : B(a) \to \wtypeh{x:A} B(x)$，我们有一个等式见证 $\beta(C,c,a,f)$：
    \begin{equation*}
        \rec{\wtypeh{x:A} B(x)}(C,c,\supp(a,f)) =
        c(a,\lamu{b:B(a)} \rec{\wtypeh{x:A} B(x)}(C,c,f(b)))。
    \end{equation*}
\end{itemize}

此外，我们断言以下唯一性原则，表明由相同递归定义的任何两个函数是相等的：
\index{uniqueness!principle, propositional!for homotopy W-types@for homotopy $\w$-types}%
\begin{itemize}
    \item 设 $C : \type$ 和 $c : \prd{a:A} (B(a) \to C) \to C$ 给定。设 $g,h : (\wtypeh{x:A} B(x)) \to C$ 是两个函数，它们在命题相等性上满足递归 $c$，即我们有
    \begin{align*}
        \beta_g &: \prd{a,f} \id{g(\supp(a,f))}{c(a,\lamu{b: B(a)} g(f(b)))}，\\
        \beta_h &: \prd{a,f} \id{h(\supp(a,f))}{c(a,\lamu{b: B(a)} h(f(b)))}。
    \end{align*}
    那么 $g$ 和 $h$ 是相等的，即存在 $\alpha(C,c,f,g,\beta_g,\beta_h)$ 类型 $g = h$ 的元素。
\end{itemize}

\index{coherence}%
回想一下，当我们有一个归纳原理而不仅仅是递归原理时，这种命题唯一性原则是可导出的（见 \cref{thm:w-uniq}）。但仅有递归时，唯一性原则不再是可导出的——事实上，该陈述甚至不是真的（练习题）。因此，我们将其作为一个公理来假设。我们还假设以下一致性法则，告诉我们唯一性证明在典型元素上的行为：
\begin{itemize}
    \item
    对于任何 $a : A$ 和 $f : B(a) \to C$，以下图命题性地交换：
    \[\xymatrix{
        g(\supp(a,f)) \ar_{\alpha(\supp(a,f))}[d] \ar^-{\beta_g}[r] & c(a,\lamu{b:B(a)} g(f(b)))
        \ar^{c(a,\blank)(\funext (\lam{b} \alpha(f(b))))}[d] \\
        h(\supp(a,f)) \ar_-{\beta_h}[r] & c(a,\lamu{b: B(a)} h(f(b))) \\
    }\]
    其中 $\alpha$ 是路径 $\alpha(C,c,f,g,\beta_g,\beta_h) : g = h$ 的缩写。
\end{itemize}

将所有这些数据结合起来得出 $\wtype{x:A} B(x)$ 的另一种表征，即配有上确界函数、满足简单消去、计算、唯一性和一致性规则的类型：
\begin{multline*}
    \w_s(A,B) \defeq \sm{W : \type}
    \sm{\supp : \prd {a} (B(a) \to W) \to W}
    \prd{C : \type}
    \prd{c : \prd{a} (B(a) \to C) \to C}\\
    \sm{\rec{} : W \to C}
    \sm{\beta : \prd{a,f} \rec{}(\supp(a,f)) = c(a,\lamu{b: B(a)} \rec{}(f(b)))} \narrowbreak
    \prd{g : W \to C}
    \prd{h : W \to C}
    \prd{\beta_g : \prd{a,f} g(\supp(a,f)) = c(a,\lamu{b: B(a)} g(f(b)))} \\
    \prd{\beta_h : \prd{a,f} h(\supp(a,f)) = c(a,\lamu{b: B(a)} h(f(b)))}
    \sm{\alpha : \prd {w : W} g(w) = h(w)}
    \prd{a,f} \\
    \alpha(\supp(a,f)) \ct \beta_h = \beta_g \ct c(a,-)(\funext \; \lam{b} \alpha(f(b)))
\end{multline*}

\begin{thm}
    对于任意 $A : \type$ 和 $B : A \to \type$，类型 $\w_s (A,B)$ 是一个单命题。
\end{thm}

最后，我们有一个第三个非常简洁的表征，将 $\wtype{x:A} B(x)$ 作为同伦初始的 $\w$-代数：
\begin{equation*}
    \w_h(A,B) \defeq \sm{I : \walg(A,B)} \ishinitw(A,B,I)。
\end{equation*}

\begin{thm}
    对于任意 $A : \type$ 和 $B : A \to \type$，类型 $\w_h (A,B)$ 是一个单命题。
\end{thm}

事实证明，所有三个 $\w$-类型的表征实际上是等价的：
\begin{lem}\label{lem:homotopy-induction-times-3}
对于任意 $A : \type$ 和 $B : A \to \type$，我们有
\[ \w_d(A,B) \eqvsym \w_s(A,B) \eqvsym \w_h(A,B) \]
\end{lem}

实际上，我们有以下定理，这比 \cref{thm:w-hinit} 更进一步：

\begin{thm}
    满足 $\w$-类型的构造、引入、消去和命题计算规则的类型正是同伦初始的 $\w$-代数。
\end{thm}

%%%%%
\begin{proof}[证明概述]
%%%%%
    检查 \cref{thm:w-hinit} 的证明，我们发现只需要\emph{命题性}计算规则即可证明 $\wtype{x:A}B(x)$ 的同伦初始性。对于相反的推论，我们假设关联到 $A : \type$ 和 $B : A \to \UU$ 的多项式函子具有一个同伦初始代数 $(W,s_W)$；我们证明 $W$ 满足 $\w$-类型的命题性规则。$\w$-引入规则是简单的；即，对于 $a : A$ 和 $t : B(a) \rightarrow W$，我们定义 $\supp(a,t) : W$ 为将结构映射 $s_W : PW \rightarrow W$ 应用于 $(a,t) : PW$ 的结果。对于 $\w$-消去规则，假设其前提，特别是 $C' : W \to \type$。使用其他前提，可以证明类型 $C \defeq \sm{ w : W} C'(w)$ 可以配备一个结构映射 $s_C : PC \rightarrow C$。通过 $W$ 的同伦初始性，我们获得了一个代数同态 $(f, s_f) : (W, s_W) \rightarrow (C, s_C)$。此外，第一投影 $\proj1 : C \rightarrow W$ 可以配备一个同态的结构，因此我们得到如下形式的图
    \[
        \xymatrix{
            PW \ar[r]^{Pf} \ar[d]_{s_W}  & PC \ar[d]^{s_C}  \ar[r]^{P \proj1}  & PW  \ar[d]^{s_W}  \\
            W \ar[r]_f  & C \ar[r]_{\proj1}  & W.}
    \]
    但是，恒等函数 $1_W : W \rightarrow W$ 有一个代数同态的标准结构，因此，通过 $(W,s_W)$ 到自身的同态类型的可收缩性，复合 $(f,s_f)$ 和 $(\proj1, s_{\proj1})$ 必然存在一个等式证明，并且 $(1_W, s_{1_W})$。这特别意味着存在一个等式证明 $p :  \proj1 \circ f = 1_W$。

    由于 $(\proj2 \circ f) w : C( (\proj1 \circ f) w)$，我们可以定义
    \[
        \rec{}(w,c) \defeq
        p_{\, * \,}( ( \proj2 \circ  f)   w )   : C(w)
    \]
    其中传输 $p_{\, * \,}$ 是相对于家庭
    \[
        \lamu{u}C\circ u : (W\to W)\to W\to \UU。
    \]
    验证命题 $\w$-计算规则是一个计算，涉及形式 $p_{\, * \,}$ 的操作的自然性。
\end{proof}
%%%%%

\index{natural numbers!encoded as a W-type@encoded as a $\w$-type}%
最后，正如所愿，我们可以将同伦自然数编码为同伦 $\w$-类型：

\begin{thm}
    可以从 $\w$-类型的命题计算规则中推导出带有命题计算规则的自然数规则。
\end{thm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{The general syntax of inductive definitions}
\label{sec:strictly-positive}

\index{type!inductive|(}%
\indexsee{inductive!type}{type, inductive}%

So far, we have been discussing only particular inductive types: $\emptyt$, $\unit$, $\bool$, $\nat$, coproducts, products, $\Sigma$-types, $\w$-types, etc.
However, an important aspect of type theory is the ability to define \emph{new} inductive types, rather than being restricted only to some particular fixed list of them.
In order to be able to do this, however, we need to know what sorts of ``inductive definitions'' are valid or reasonable.

To see that not everything which ``looks like an inductive definition'' makes sense, consider the following ``constructor'' of a type $C$:
\begin{itemize}
\item $g:(C\to \nat) \to C$.
\end{itemize}
The recursion principle for such a type $C$ ought to say that given a type $P$, in order to construct a function $f:C\to P$, it suffices to consider the case when the input $c:C$ is of the form $g(\alpha)$ for some $\alpha:C\to\nat$.
Moreover, we would expect to be able to use the ``recursive data'' of $f$ applied to $\alpha$ in some way.
However, it is not at all clear how to ``apply $f$ to $\alpha$'', since both are functions with domain $C$.

We could write down a ``recursion principle'' for $C$ by just supposing (unjustifiably) that there is some way to apply $f$ to $\alpha$ and obtain a function $P\to\nat$.
Then the input to the recursion rule would ask for a type $P$ together with a function
\begin{equation}
  h:(C\to\nat) \to (P\to\nat) \to P\label{eq:fake-recursor}
\end{equation}
where the two arguments of $h$ are $\alpha$ and ``the result of applying $f$ to $\alpha$''.
However, what would the computation rule for the resulting function $f:C\to P$ be?
Looking at other computation rules, we would expect something like ``$f(g(\alpha)) \jdeq h(\alpha,f(\alpha))$'' for $\alpha:C\to\nat$, but as we have seen, ``$f(\alpha)$'' does not make sense.
The induction principle of $C$ is even more problematic; it's not even clear how to write down the hypotheses.

On the other hand, we could write down a different ``recursion principle'' for $C$ by ignoring the ``recursive'' presence of $C$ in the domain of $\alpha$, considering it as merely an indexing type for a family of natural numbers.
In this case the input would ask for a type $P$ together with a function
\begin{equation*}
  h:(C\to \nat) \to P,
\end{equation*}
so the type of the recursion principle would be $\rec{C}:\prd{P:\UU} ((C\to \nat) \to P) \to C\to P$, and similarly for the induction principle.
Now it is possible to write down a computation rule, namely $\rec{C}(P,h,g(\alpha))\jdeq h(\alpha)$.
However, the existence of a type $C$ with this recursor and computation rule turns out to be inconsistent.
See \cref{ex:loop,ex:loop2,ex:inductive-lawvere,ex:ilunit} for proofs of this and other variations.

This example suggests one restriction on inductive definitions: the domains of all the constructors must be \emph{covariant functors}\index{functor!covariant}\index{covariant functor} of the type being defined, so that we can ``apply $f$ to them'' to get the result of the ``recursive call''.
In other words, if we replace all occurrences of the type being defined with a variable
\index{variable!type}%
$X:\type$, then each domain of a constructor
\index{domain!of a constructor}%
must be an expression that can be made into a covariant functor of $X$.
This is the case for all the examples we have considered so far.
For instance, with the constructor $\inl:A\to A+B$, the relevant functor is constant at $A$ (i.e.\ $X\mapsto A$), while for the constructor $\suc:\nat\to\nat$, the functor is the identity functor ($X\mapsto X$).

However, this necessary condition is also not sufficient.
Covariance prevents the inductive type from occurring on the left of a single function type, as in the argument $C\to\nat$ of the ``constructor'' $g$ considered above, since this yields a contravariant\index{functor!contravariant}\index{contravariant functor} functor rather than a covariant one.
However, since the composite of two contravariant functors is covariant, \emph{double} function types such as $((X\to \nat)\to \nat)$ are once again covariant.
This enables us to reproduce Cantorian-style paradoxes\index{paradox}.

For instance, consider an ``inductive type'' $D$ with the following constructor:
\begin{itemize}
\item $k:((D\to\prop)\to\prop)\to D$.
\end{itemize}
Assuming such a type exists, we define functions
\begin{align*}
  r&:D\to (D\to\prop)\to\prop,\\
  f&:(D\to\prop) \to D,\\
  p&:(D\to \prop) \to (D\to\prop)\to \prop,\\
  \intertext{by}
  r(k(\theta)) &\defeq \theta,\\
  f(\delta) &\defeq k(\lam{x} (x=\delta)),\\
  p(\delta) &\defeq \lam{x} \delta(f(x)).
\end{align*}
Here $r$ is defined by the recursion principle of $D$, while $f$ and $p$ are defined explicitly.
Then for any $\delta:D\to\prop$, we have $r(f(\delta)) = \lam{x}(x=\delta)$.

In particular, therefore, if $f(\delta)=f(\delta')$, then we have a path $s:(\lam{x}(x=\delta)) = (\lam{x}(x=\delta'))$.
Thus, $\happly(s,\delta) : (\delta=\delta) = (\delta=\delta')$, and so in particular $\delta=\delta'$ holds.
Hence, $f$ is ``injective'' (although \emph{a priori} $D$ may not be a set).
This already sounds suspicious --- we have an ``injection'' of the ``power set''\index{power set} of $D$ into $D$ --- and with a little more work we can massage it into a contradiction.

Suppose given $\theta:(D\to\prop)\to\prop$, and define $\delta:D\to\prop$ by
\begin{equation}
  \delta(d) \defeq \exis{\gamma:D\to\prop} (f(\gamma) = d) \times \theta(\gamma).\label{eq:Pinj}
\end{equation}
We claim that $p(\delta)=\theta$.
By function extensionality, it suffices to show $p(\delta)(\gamma) =_\prop \theta(\gamma)$ for any $\gamma:D\to\prop$.
And by univalence, for this it suffices to show that each implies the other.
Now by definition of $p$, we have
\begin{align*}
  p(\delta)(\gamma) &\jdeq \delta(f(\gamma))\\
  &\jdeq \exis{\gamma':D\to\prop} (f(\gamma') = f(\gamma)) \times \theta(\gamma').
\end{align*}
Clearly this holds if $\theta(\gamma)$, since we may take $\gamma'\defeq \gamma$.
On the other hand, if we have $\gamma'$ with $f(\gamma') = f(\gamma)$ and $\theta(\gamma')$, then $\gamma'=\gamma$ since $f$ is injective, hence also $\theta(\gamma)$.

This completes the proof that $p(\delta)=\theta$.
Thus, every element $\theta:(D\to\prop)\to\prop$ is the image under $p$ of some element $\delta:D\to\prop$.
However, if we define $\theta$ by a classic diagonalization:
\[ \theta(\gamma) \defeq \neg p(\gamma)(\gamma) \quad\text{for all $\gamma:D\to\prop$} \]
then from $\theta = p(\delta)$ we deduce $p(\delta)(\delta) = \neg p(\delta)(\delta)$.
This is a contradiction: no proposition can be equivalent to its negation.
(Supposing $P\Leftrightarrow \neg P$, if $P$, then $\neg P$, and so $\emptyt$; hence $\neg P$, but then $P$, and so $\emptyt$.)

\begin{rmk}
  There is a question of universe size to be addressed.
  In general, an inductive type must live in a universe that already contains all the types going into its definition.
  Thus if in the definition of $D$, the ambiguous notation \prop means $\prop_{\UU}$, then we do not have $D:\UU$ but only $D:\UU'$ for some larger universe $\UU'$ with $\UU:\UU'$.
  \index{mathematics!predicative}%
  \indexsee{impredicativity}{mathematics, predicative}%
  \indexsee{predicative mathematics}{mathematics, predicative}%
  In a predicative theory, therefore, the right-hand side of~\eqref{eq:Pinj} lives in $\prop_{\UU'}$, not $\prop_\UU$.
  So this contradiction does require the propositional resizing axiom
  \index{propositional!resizing}%
  mentioned in \cref{subsec:prop-subsets}.
\end{rmk}

\index{consistency}%
This counterexample suggests that we should ban an inductive type from ever appearing on the left of an arrow in the domain of its constructors, even if that appearance is nested in other arrows so as to eventually become covariant.
(Similarly, we also forbid it from appearing in the domain of a dependent function type.)
This restriction is called \define{strict positivity}
\indexdef{strict!positivity}%
\indexsee{positivity, strict}{strict positivity}%
(ordinary ``positivity'' being essentially covariance), and it turns out to suffice.

\index{constructor}%
In conclusion, therefore, a valid inductive definition of a type $W$ consists of a list of \emph{constructors}.
Each constructor is assigned a type that is a function type taking some number (possibly zero) of inputs (possibly dependent on one another) and returning an element of $W$.
Finally, we allow $W$ itself to occur in the input types of its constructors, but only strictly positively.
This essentially means that each argument of a constructor is either a type not involving $W$, or some iterated function type with codomain $W$.
For instance, the following is a valid constructor type:
\begin{equation}
  c:(A\to W) \to (B\to C \to W) \to D \to W \to W.\label{eq:example-constructor}
\end{equation}
All of these function types can also be dependent functions ($\Pi$-types).%
\footnote{In the language of \cref{sec:initial-alg}, the condition of strict positivity ensures that the relevant endofunctor is polynomial.\indexfoot{endofunctor!polynomial}\indexfoot{algebra!initial}\indexsee{algebra!initial}{homotopy-initial} It is well-known in category theory that not \emph{all} endofunctors can have initial algebras; restricting to polynomial functors ensures consistency.
One can consider various relaxations of this condition, but in this book we will restrict ourselves to strict positivity as defined here.}

Note we require that an inductive definition is given by a \emph{finite} list of constructors.
This is simply because we have to write it down on the page.
If we want an inductive type which behaves as if it has an infinite number of constructors, we can simply parametrize one constructor by some infinite type.
For instance, a constructor such as $\nat \to W \to W$ can be thought of as equivalent to countably many constructors of the form $W\to W$.
(Of course, the infinity is now \emph{internal} to the type theory, but this is as it should be for any foundational system.)
Similarly, if we want a constructor that takes ``infinitely many arguments'', we can allow it to take a family of arguments parametrized by some infinite type, such as $(\nat\to W) \to W$ which takes an infinite sequence\index{sequence} of elements of $W$.

\index{recursion principle!for an inductive type}%
Now, once we have such an inductive definition, what can we do with it?
Firstly, there is a \define{recursion principle} stating that in order to define a function $f:W\to P$, it suffices to consider the case when the input $w:W$ arises from one of the constructors, allowing ourselves to recursively call $f$ on the inputs to that constructor.
For the example constructor~\eqref{eq:example-constructor}, we would require $P$ to be equipped with a function of type
\begin{narrowmultline}\label{eq:example-rechyp}
  d : (A\to W) \to (A\to P) \to (B\to C\to W) \to
  \narrowbreak
  (B\to C \to P) \to D \to W \to P \to P.
\end{narrowmultline}
Under these hypotheses, the recursion principle yields $f:W\to P$, which moreover ``preserves the constructor data'' in the evident way --- this is the computation rule, where we use covariance of the inputs.
\index{computation rule!for inductive types}%
For instance, in the example~\eqref{eq:example-constructor}, the computation rule says that for any $\alpha:A\to W$, $\beta:B\to C\to W$, $\delta:D$, and $\omega:W$, we have
\begin{equation}
  f(c(\alpha,\beta,\delta,\omega)) \jdeq d(\alpha,f\circ \alpha,\beta, f\circ \beta, \delta, \omega,f(\omega)).\label{eq:example-comp}
\end{equation}
% As we have before in particular cases, when defining a particular function $f$, we may write these rules with $\defeq$ as a way of specifying the data $d$, and say that $f$ is defined by them.

\index{induction principle!for an inductive type}%
The \define{induction principle} for a general inductive type $W$ is only a little more complicated.
Of course, we start with a type family $P:W\to\type$, which we require to be equipped with constructor data ``lying over'' the constructor data of $W$.
That means the ``recursive call'' arguments such as $A\to P$ above must be replaced by dependent functions with types such as $\prd{a:A} P(\alpha(a))$.
In the full example of~\eqref{eq:example-constructor}, the corresponding hypothesis for the induction principle would require
\begin{multline}\label{eq:example-indhyp}
d : \prd{\alpha:A\to W}\Parens{\prd{a:A} P(\alpha(a))} \to \narrowbreak
\prd{\beta:B\to C\to W} \Parens{\prd{b:B}{c:C} P(\beta(b,c))} \to\\
\prd{\delta:D}
\prd{\omega:W} P(\omega) \to
P(c(\alpha,\beta,\delta,\omega)).
\end{multline}
The corresponding computation rule looks identical to~\eqref{eq:example-comp}.
Of course, the recursion principle is the special case of the induction principle where $P$ is a constant family.
As we have mentioned before, the induction principle is also called the \define{eliminator}, and the recursion principle the \define{non-dependent eliminator}.

As discussed in \cref{sec:pattern-matching}, we also allow ourselves to invoke the induction and recursion principles implicitly, writing a definitional equation with $\defeq$ for each expression that would be the hypotheses of the induction principle.
This is called giving a definition by (dependent) \define{pattern matching}.
\index{pattern matching}%
\index{definition!by pattern matching}%
In our running example, this means we could define $f:\prd{w:W} P(w) $ by
\[ f(c(\alpha,\beta,\delta,\omega)) \defeq \cdots \]
where $\alpha:A\to W$ and $\beta:B\to C\to W$ and $\delta:D$ and $\omega:W$ are variables
\index{variable}%
that are bound in the right-hand side.
Moreover, the right-hand side may involve recursive calls to $f$ of the form $f(\alpha(a))$, $f(\beta(b,c))$, and $f(\omega)$.
When this definition is repackaged in terms of the induction principle, we replace such recursive calls by $\bar\alpha(a)$, $\bar\beta(b,c)$, and $\bar\omega$, respectively, for new variables
\begin{align*}
  \bar\alpha &: \prd{a:A} P(\alpha(a))\\
  \bar\beta &: \prd{b:B}{c:C} P(\beta(b,c))\\
  \bar\omega &: P(\omega).
\end{align*}
\symlabel{defn:induction-wtype}%
Then we could write
\[ f \defeq \ind{W}(P,\, \lam{\alpha}{\bar\alpha}{\beta}{\bar\beta}{\delta}{\omega}{\bar\omega} \cdots ) \]
where the second argument to $\ind{W}$ has the type of~\eqref{eq:example-indhyp}.

We will not attempt to give a formal presentation of the grammar of a valid inductive definition and its resulting induction and recursion principles and pattern matching rules.
This is possible to do (indeed, it is necessary to do if implementing a computer proof assistant), but provides no additional insight.
With practice, one learns to automatically deduce the induction and recursion principles for any inductive definition, and to use them without having to think twice.


\section{Generalizations of inductive types}
\label{sec:generalizations}

\index{type!inductive!generalizations}%
The notion of inductive type has been studied in type theory for many years, and admits many, many generalizations: inductive type families, mutual inductive types, inductive-inductive types, inductive-recur\-sive types, etc.
In this section we give an overview of some of these, a few of which will be used later in the book.
(In \cref{cha:hits} we will study in more depth a very different generalization of inductive types, which is particular to \emph{homotopy} type theory.)

Most of these generalizations involve allowing ourselves to define more than one type by induction at the same time.
One very simple example of this, which we have already seen, is the coproduct $A+B$.
It would be tedious indeed if we had to write down separate inductive definitions for $\nat+\nat$, for $\nat+\bool$, for $\bool+\bool$, and so on every time we wanted to consider the coproduct of two types.
Instead, we make one definition in which $A$ and $B$ are variables standing for types;
\index{variable!type}%
in type theory they are called \define{parameters}.%
\indexdef{parameter!of an inductive definition}
Thus technically speaking, what results from the definition is not a single type, but a family of types $+ : \type\to\type\to\type$, taking two types as input and producing their coproduct.
Similarly, the type $\lst A$ of lists\index{type!of lists} is a family $\lst{\blank}:\type\to\type$ in which the type $A$ is a parameter.

In mathematics, this sort of thing is so obvious as to not be worth mentioning, but we bring it up in order to contrast it with the next example.
Note that each type $A+B$ is \emph{independently} defined inductively, as is each type $\lst A$.
\index{type!family of!inductive}%
\index{inductive!type family}%
By contrast, we might also consider defining a whole type family $B:A\to\type$ by induction \emph{together}.
The difference is that now the constructors may change the index $a:A$, and as a consequence we cannot say that the individual types $B(a)$ are inductively defined, only that the entire family is inductively defined.

\index{type!of vectors}%
\index{vector}%
The standard example is the type of \emph{lists of specified length}, traditionally called \define{vectors}.
We fix a parameter type $A$, and define a type family $\vect n A$, for $n:\nat$, generated by the following constructors:
\begin{itemize}
\item a vector $\nil:\vect 0 A$ of length zero,
\item a function $\cons:\prd{n:\nat} A\to \vect n A \to \vect{\suc (n)} A$.
\end{itemize}
In contrast to lists, vectors (with elements from a fixed type $A$) form a family of types indexed by their length.
While $A$ is a parameter, we say that $n:\nat$ is an \define{index}
\indexdef{index of an inductive definition}%
of the inductive family.
An individual type such as $\vect3A$ is not inductively defined: the constructors which build elements of $\vect3A$ take input from a different type in the family, such as $\cons:A \to \vect2A \to \vect3A$.

\index{induction principle!for type of vectors}
\index{vector!induction principle for}
In particular, the induction principle must refer to the entire type family as well; thus the hypotheses and the conclusion must quantify over the indices appropriately.
In the case of vectors, the induction principle states that given a type family $C:\prd{n:\nat} \vect n A \to \type$, together with
\begin{itemize}
\item an element $c_\nil : C(0,\nil)$, and
\item a function \narrowequation{c_\cons : \prd{n:\nat}{a:A}{\ell:\vect n A} C(n,\ell) \to C(\suc(n),\cons(a,\ell))}
\end{itemize}
there exists a function $f:\prd{n:\nat}{\ell:\vect n A} C(n,\ell)$ such that
\begin{align*}
  f(0,\nil) &\jdeq c_\nil\\
  f(\suc(n),\cons(a,\ell)) &\jdeq c_\cons(n,a,\ell,f(\ell)).
\end{align*}

\index{predicate!inductive}%
\index{inductive!predicate}%
One use of inductive families is to define \emph{predicates} inductively.
For instance, we might define the predicate $\mathsf{iseven}:\nat\to\type$ as an inductive family indexed by $\nat$, with the following constructors:
\begin{itemize}
\item an element $\mathsf{even}_0 : \mathsf{iseven}(0)$,
\item a function $\mathsf{even}_{ss} : \prd{n:\nat} \mathsf{iseven}(n) \to \mathsf{iseven}(\suc(\suc(n)))$.
\end{itemize}
In other words, we stipulate that $0$ is even, and that if $n$ is even then so is $\suc(\suc(n))$.
These constructors ``obviously'' give no way to construct an element of, say, $\mathsf{iseven}(1)$, and since $\mathsf{iseven}$ is supposed to be freely generated by these constructors, there must be no such element.
(Actually proving that $\neg \mathsf{iseven}(1)$ is not entirely trivial, however).
The induction principle for $\mathsf{iseven}$ says that to prove something about all even natural numbers, it suffices to prove it for $0$ and verify that it is preserved by adding two.

\index{mathematics!formalized}%
Inductively defined predicates are much used in computer formalization of mathematics and software verification.
But we will not have much use for them, with a couple of exceptions in \cref{sec:ordinals,sec:compactness-interval}.

\index{type!mutual inductive}%
\index{mutual inductive type}%
Another important special case is when the indexing type of an inductive family is finite.
In this case, we can equivalently express the inductive definition as a finite collection of types defined by \emph{mutual induction}.
For instance, we might define the types $\mathsf{even}$ and $\mathsf{odd}$ of even and odd natural numbers by mutual induction, where $\mathsf{even}$ is generated by constructors
\begin{itemize}
\item $0:\mathsf{even}$ and
\item $\mathsf{esucc} : \mathsf{odd}\to\mathsf{even}$,
\end{itemize}
while $\mathsf{odd}$ is generated by the one constructor
\begin{itemize}
\item $\mathsf{osucc} : \mathsf{even}\to \mathsf{odd}$.
\end{itemize}
Note that $\mathsf{even}$ and $\mathsf{odd}$ are simple types (not type families), but their constructors can refer to each other.
If we expressed this definition as an inductive type family $\mathsf{paritynat} : \bool \to \type$, with $\mathsf{paritynat}(\bfalse)$ and $\mathsf{paritynat}(\btrue)$ representing $\mathsf{even}$ and $\mathsf{odd}$ respectively, it would instead have constructors:
\begin{itemize}
\item $0 : \mathsf{paritynat}(\bfalse)$,
\item $\mathsf{esucc} : \mathsf{paritynat}(\btrue) \to \mathsf{paritynat}(\bfalse)$,
\item $\mathsf{osucc} : \mathsf{paritynat}(\bfalse) \to \mathsf{paritynat}(\btrue)$.
\end{itemize}
When expressed explicitly as a mutual inductive definition, the induction principle for $\mathsf{even}$ and $\mathsf{odd}$ says that given $C:\mathsf{even}\to\type$ and $D:\mathsf{odd}\to\type$, along with
\begin{itemize}
\item $c_0 : C(0)$,
\item $c_s : \prd{n:\mathsf{odd}} D(n) \to C(\mathsf{esucc}(n))$,
\item $d_s : \prd{n:\mathsf{even}} C(n) \to D(\mathsf{osucc}(n))$,
\end{itemize}
there exist $f:\prd{n:\mathsf{even}} C(n)$ and $g:\prd{n:\mathsf{odd}}D(n)$ such that
\begin{align*}
  f(0) &\jdeq c_0\\
  f(\mathsf{esucc}(n)) &\jdeq c_s(g(n))\\
  g(\mathsf{osucc}(n)) &\jdeq d_s(f(n)).
\end{align*}
In particular, just as we can only induct over an inductive family ``all at once'', we have to induct on $\mathsf{even}$ and $\mathsf{odd}$ simultaneously.
We will not have much use for mutual inductive definitions in this book either.

\index{type!inductive-inductive}%
\index{inductive-inductive type}%
A further, more radical, generalization is to allow definition of a type family $B:A\to \type$ in which not only the types $B(a)$, but the type $A$ itself, is defined as part of one big induction.
In other words, not only do we specify constructors for the $B(a)$s which can take inputs from other $B(a')$s, as with inductive families, we also at the same time specify constructors for $A$ itself, which can take inputs from the $B(a)$s.
This can be regarded as an inductive family in which the indices are inductively defined simultaneously with the indexed types, or as a mutual inductive definition in which one of the types can depend on the other.
More complicated dependency structures are also possible.
In general, these are called \define{inductive-inductive definitions}.
For the most part, we will not use them in this book, but their higher variant (see \cref{cha:hits}) will appear in a couple of experimental examples in \cref{cha:real-numbers}.

\index{type!inductive-recursive}%
\index{inductive-recursive type}%
The last generalization we wish to mention is \define{inductive-recursive definitions}, in which a type is defined inductively at the same time as a \emph{recursive} function on it.
That is, we fix a known type $P$, and give constructors for an inductive type $A$ and at the same time define a function $f:A\to P$ using the recursion principle for $A$ resulting from its constructors --- with the twist that the constructors of $A$ are allowed to refer also to the values of $f$.
We do not yet know how to justify such definitions from a homotopical perspective, and we will not use any of them in this book.

\index{type!inductive|)}%

\section{Identity types and identity systems}
\label{sec:identity-systems}

\index{type!identity!as inductive}%
We now wish to point out that the \emph{identity types}, which play so central a role in homotopy type theory, may also be considered to be defined inductively.
Specifically, they are an ``inductive family'' with indices, in the sense of \cref{sec:generalizations}.
In fact, there are \emph{two} ways to describe identity types as an
inductive family, resulting in the two induction principles described in
\cref{cha:typetheory}, path induction and based path induction.

In both definitions, the type $A$ is a parameter.
For the first definition, we inductively define a family $=_A : A\to A\to \type$, with two indices belonging to $A$, by the following constructor:
\begin{itemize}
\item for any $a:A$, an element $\refl a : a=_A a$.
\end{itemize}
By analogy with the other inductive families, we may extract the induction principle from this definition.
It states that given any \narrowequation{C:\prd{a,b:A} (a=_A b) \to \type,} along with $d:\prd{a:A} C(a,a,\refl{a})$, there exists \narrowequation{f:\prd{a,b:A}{p:a=_A b} C(a,b,p)} such that $f(a,a,\refl a)\jdeq d(a)$.
This is exactly the path induction principle for identity types.

For the second definition, we consider one element $a_0:A$ to be a parameter along with $A:\type$, and we inductively define a family $(a_0 =_A \blank):A\to \type$, with \emph{one} index belonging to $A$, by the following constructor:
\begin{itemize}
\item an element $\refl{a_0} : a_0 =_A a_0$.
\end{itemize}
Note that because $a_0:A$ was fixed as a parameter, the constructor $\refl{a_0}$ does not appear inside the inductive definition as a function, but only as an element.
The induction principle for this definition says that given $C:\prd{b:A} (a_0 =_A b) \to \type$ along with an element $d:C(a_0,\refl{a_0})$, there exists $f:\prd{b:A}{p:a_0 =_A b} C(b,p)$ with $f(a_0,\refl{a_0})\jdeq d$.
This is exactly the based path induction principle for identity types.

The view of identity types as inductive types has historically caused some confusion, because of the intuition mentioned in \cref{sec:bool-nat} that all the elements of an inductive type should be obtained by repeatedly applying its constructors.
For ordinary inductive types such as \bool and \nat, this is the case: we saw in \cref{thm:allbool-trueorfalse} that indeed every element of \bool is either $\bfalse$ or $\btrue$, and similarly one can prove that every element of \nat is either $0$ or a successor.

However, this is \emph{not} true for identity types: there is only one constructor $\refl{}$, but not every path is equal to the constant path.
More precisely, we cannot prove, using only the induction principle for identity types (either one), that every inhabitant of $a=_A a$ is equal to $\refl a$.
In order to actually exhibit a counterexample, we need some additional principle such as the univalence axiom --- recall that in \cref{thm:type-is-not-a-set} we used univalence to exhibit a particular path $\bool=_\type\bool$ which is not equal to $\refl{\bool}$.

\index{free!generation of an inductive type}%
\index{generation!of a type, inductive|(}%
The point is that, as validated by the study of homotopy-initial algebras, an inductive definition should be regarded as \emph{freely generated} by its constructors.
Of course, a freely generated structure may contain elements other than its generators: for instance, the free group on two symbols $x$ and $y$ contains not only $x$ and $y$ but also words such as $xy$, $yx^{-1}y$, and $x^3y^2x^{-2}yx$.
In general, the elements of a free structure are obtained by applying not only the generators, but also the operations of the ambient structure, such as the group operations if we are talking about free groups.

In the case of inductive types, we are talking about freely generated \emph{types} --- so what are the ``operations'' of the structure of a type?
If types are viewed as like \emph{sets}, as was traditionally the case in type theory, then there are no such operations, and hence we expect there to be no elements in an inductive type other than those resulting from its constructors.
In homotopy type theory, we view types as like \emph{spaces} or $\infty$-groupoids,%
\index{.infinity-groupoid@$\infty$-groupoid}
in which case there are many operations on the \emph{paths} (concatenation, inversion, etc.) --- this will be important in \cref{cha:hits} --- but there are still no operations on the \emph{objects} (elements).
Thus, it is still true for us that, e.g., every element of \bool is either $\bfalse$ or $\btrue$, and every element of $\nat$ is either $0$ or a successor.

However, as we saw in \cref{cha:basics}, viewing types as $\infty$-groupoids entails also viewing functions as functors, and this includes type families $B:A\to\type$.
Thus, the identity type $(a_0 =_A \blank)$, viewed as an inductive type family, is actually a \emph{freely generated functor} $A\to\type$.
Specifically, it is the functor $F:A\to\type$ freely generated by one element $\refl{a_0}: F(a_0)$.
And a functor does have operations on objects, namely the action of the morphisms (paths) of $A$.

In category theory, the \emph{Yoneda lemma}\index{Yoneda!lemma} tells us that for any category $A$ and object $a_0$, the functor freely generated by an element of $F(a_0)$ is the representable functor $\hom_A(a_0,\blank)$.
Thus, we should expect the identity type $(a_0 =_A \blank)$ to be this representable functor, and this is indeed exactly how we view it: $(a_0 =_A b)$ is the space of morphisms (paths) in $A$ from $a_0$ to $b$.

\index{generation!of a type, inductive|)}

\mentalpause

One reason for viewing identity types as inductive families is to apply the uniqueness principles of \cref{sec:appetizer-univalence,sec:htpy-inductive}.
Specifically, we can characterize the family of identity types of a type $A$, up to equivalence, by giving another family of types over $A\times A$ satisfying the same induction principle.
This suggests the following definitions and theorem.

\indexsee{system, identity}{identity system}%
\index{identity!system!at a point|(defstyle}%

\begin{defn}\label{defn:identity-systems}
  Let $A$ be a type and $a_0:A$ an element.
  \begin{itemize}
  \item A \define{pointed predicate}
    \indexdef{predicate!pointed}%
    \indexdef{pointed!predicate}%
    over $(A,a_0)$ is a family $R:A\to\type$ equipped with an element $r_0:R(a_0)$.
  \item For pointed predicates $(R,r_0)$ and $(S,s_0)$, a family of maps $g:\prd{b:A} R(b) \to S(b)$ is \define{pointed} if $g(a_0, r_0)=s_0$.
    We have
    \[ \mathsf{ppmap}(R,S) \defeq \sm{g:\prd{b:A} R(b) \to S(b)} (g(a_0, r_0)=s_0).\]
  \item An \define{identity system at $a_0$}
    is a pointed predicate $(R,r_0)$ such that for any type family $D:\prd{b:A} R(b) \to \type$ and $d:D(a_0,r_0)$, there exists a function $f:\prd{b:A}{r:R(b)} D(b,r)$ such that $f(a_0,r_0)=d$.
\end{itemize}
\end{defn}

\begin{thm}\label{thm:identity-systems}
  For a pointed predicate $(R,r_0)$ over $(A,a_0)$, the following are logically equivalent.
  \begin{enumerate}
  \item $(R,r_0)$ is an identity system at $a_0$.\label{item:identity-systems1}
  \item For any pointed predicate $(S,s_0)$, the type $\mathsf{ppmap}(R,S)$ is contractible.\label{item:identity-systems2}
  \item For any $b:A$, the function $\transfib{R}{\blank}{r_0} : (a_0 =_A b) \to R(b)$ is an equivalence.\label{item:identity-systems3}
  \item The type $\sm{b:A} R(b)$ is contractible.\label{item:identity-systems4}
  \end{enumerate}
\end{thm}

Note that the equivalences~\ref{item:identity-systems1}$\Leftrightarrow$\ref{item:identity-systems2}$\Leftrightarrow$\ref{item:identity-systems3} are a version of \cref{lem:homotopy-induction-times-3} for identity types $a_0 =_A \blank$, regarded as inductive families varying over one element of $A$.
Of course,~\ref{item:identity-systems2}--\ref{item:identity-systems4} are mere propositions, so that logical equivalence implies actual equivalence.
(Condition~\ref{item:identity-systems1} is also a mere proposition, but we will not prove this.)
Note also that unlike~\ref{item:identity-systems1}--\ref{item:identity-systems3}, statement~\ref{item:identity-systems4} doesn't refer to $a_0$ or $r_0$.

\begin{proof}
  First, assume~\ref{item:identity-systems1} and let $(S,s_0)$ be a pointed predicate.
  Define $D(b,r) \defeq S(b)$ and $d\defeq s_0: S(a_0) \jdeq D(a_0,r_0)$.
  Since $R$ is an identity system, we have $f:\prd{b:A} R(b) \to S(b)$ with $f(a_0,r_0) = s_0$; hence $\mathsf{ppmap}(R,S)$ is inhabited.
  Now suppose $(f,f_r),(g,g_r) : \mathsf{ppmap}(R,S)$, and define $D(b,r) \defeq (f(b,r) = g(b,r))$, and let $d \defeq f_r \ct \opp{g_r} : f(a_0,r_0) = s_0 = g(a_0,r_0)$.
  Then again since $R$ is an identity system, we have $h:\prd{b:A}{r:R(b)} D(b,r)$ such that $h(a_0,r_0) = f_r \ct \opp{g_r}$.
  By function extensionality and the characterization of paths in $\Sigma$-types and path types, these data yield an equality $(f,f_r) = (g,g_r)$.
  Hence $\mathsf{ppmap}(R,S)$ is an inhabited mere proposition, and thus contractible; so~\ref{item:identity-systems2} holds.

  Now suppose~\ref{item:identity-systems2}, and define $S(b) \defeq (a_0=b)$ with $s_0 \defeq \refl{a_0}:S(a_0)$.
  Then $(S,s_0)$ is a pointed predicate, and $\lamu{b:B}{p:a_0=b} \transfib{R}{p}{r} : \prd{b:A} S(b) \to R(b)$ is a pointed family of maps from $S$ to $R$.
  By assumption, $\mathsf{ppmap}(R,S)$ is contractible, hence inhabited, so there also exists a pointed family of maps from $R$ to $S$.
  And the composites in either direction are pointed families of maps from $R$ to $R$ and from $S$ to $S$, respectively, hence equal to identities since $\mathsf{ppmap}(R,R)$ and $\mathsf{ppmap}(S,S)$ are contractible.
  Thus~\ref{item:identity-systems3} holds.

  Now supposing~\ref{item:identity-systems3}, condition~\ref{item:identity-systems4} follows from \cref{thm:contr-paths}, using the fact that $\Sigma$-types respect equivalences (the ``if'' direction of \cref{thm:total-fiber-equiv}).

  Finally, assume~\ref{item:identity-systems4}, and let $D:\prd{b:A} R(b)\to  \type$ and $d:D(a_0,r_0)$.
  We can equivalently express $D$ as a family $D':(\sm{b:A} R(b)) \to \type$.
  Now since $\sm{b:A} R(b)$ is contractible, we have
  \[p:\prd{u:\sm{b:A} R(b)} (a_0,r_0) = u. \]
  Moreover, since the path types of a contractible type are again contractible, we have $p((a_0,r_0)) = \refl{(a_0,r_0)}$.
  Define $f(u) \defeq \transfib{D'}{p(u)}{d}$, yielding $f:\prd{u:\sm{b:A} R(b)} D'(u)$, or equivalently $f:\prd{b:A}{r:R(b)} D(b,r)$.
  Finally, we have
  \[f(a_0,r_0) \jdeq \transfib{D'}{p((a_0,r_0))}{d} = \transfib{D'}{\refl{(a_0,r_0)}}{d} = d.\]
  Thus,~\ref{item:identity-systems1} holds.
\end{proof}

\index{identity!system!at a point|)}%

We can deduce a similar result for identity types $=_A$, regarded as a family varying over two elements of $A$.

\index{identity!system|(defstyle}%

\begin{defn}
  An \define{identity system}
  over a type $A$ is a family $R:A\to A\to \type$ equipped with a function $r_0:\prd{a:A} R(a,a)$ such that for any type family $D:\prd{a,b:A} R(a,b) \to \type$ and $d:\prd{a:A} D(a,a,r_0(a))$, there exists a function $f:\prd{a,b:A}{r:R(a,b)} D(a,b,r)$ such that $f(a,a,r_0(a))=d(a)$ for all $a:A$.
\end{defn}

\begin{thm}\label{thm:ML-identity-systems}
  For $R:A\to A\to\type$ equipped with $r_0:\prd{a:A} R(a,a)$, the following are logically equivalent.
  \begin{enumerate}
  \item $(R,r_0)$ is an identity system over $A$.\label{item:MLis1}
  \item For all $a_0:A$, the pointed predicate $(R(a_0),r_0(a_0))$ is an identity system at $a_0$.\label{item:MLis2}
  \item For any $S:A\to A\to\type$ and $s_0:\prd{a:A} S(a,a)$, the type
    \[ \sm{g:\prd{a,b:A} R(a,b) \to S(a,b)} \prd{a:A} g(a,a,r_0(a)) = s_0(a) \]
    is contractible.\label{item:MLis3}
  \item For any $a,b:A$, the map $\transfib{R(a)}{\blank}{r_0(a)} : (a =_A b) \to R(a,b)$ is an equivalence.\label{item:MLis4}
  \item For any $a:A$, the type $\sm{b:A} R(a,b)$ is contractible.\label{item:MLis5}
  \end{enumerate}
\end{thm}
\begin{proof}
  The equivalence~\ref{item:MLis1}$\Leftrightarrow$\ref{item:MLis2} follows exactly the proof of equivalence between the path induction and based path induction principles for identity types; see \cref{sec:identity-types}.
  The equivalence with~\ref{item:MLis4} and~\ref{item:MLis5} then follows from \cref{thm:identity-systems}, while~\ref{item:MLis3} is straightforward.
\end{proof}

\index{identity!system|)}%

One reason this characterization is interesting is that it provides an alternative way to state univalence and function extensionality.
\index{univalence axiom}%
The univalence axiom for a universe \UU says exactly that the type family
\[ (\eqv{\blank}{\blank}) : \UU\to\UU\to\UU \]
together with $\idfunc : \prd{A:\UU} (\eqv AA)$ satisfies \cref{thm:ML-identity-systems}\ref{item:MLis4}.
Therefore, it is equivalent to the corresponding version of~\ref{item:MLis1}, which we can state as follows.

\begin{cor}[Equivalence induction]\label{thm:equiv-induction}
  \index{induction principle!for equivalences}%
  \index{equivalence!induction}%
  Given any type family \narrowequation{D:\prd{A,B:\UU} (\eqv AB) \to \type} and function $d:\prd{A:\UU} D(A,A,\idfunc[A])$, there exists \narrowequation{f : \prd{A,B:\UU}{e:\eqv AB} D(A,B,e)} such that $f(A,A,\idfunc[A]) = d(A)$ for all $A:\UU$.
\end{cor}

In other words, to prove something about all equivalences, it suffices to prove it about identity maps.
We have already used this principle (without stating it in generality) in \cref{lem:qinv-autohtpy}.

Similarly, function extensionality says that for any $B:A\to\type$, the type family
\[ (\blank\htpy\blank) : \Parens{\prd{a:A} B(a)} \to \Parens{\prd{a:A} B(a)} \to \type
\]
together with $\lamu{f:\prd{a:A} B(a)}{a:A} \refl{f(a)}$ satisfies \cref{thm:ML-identity-systems}\ref{item:MLis4}.
Thus, it is also equivalent to the corresponding version of~\ref{item:MLis1}.

\begin{cor}[Homotopy induction]\label{thm:htpy-induction}
  \index{induction principle!for homotopies}%
  \index{homotopy!induction}%
  Given any \narrowequation{D:\prd{f,g:\prd{a:A} B(a)} (f\htpy g) \to \type} and $d:\prd{f:\prd{a:A} B(a)} D(f,f,\lam{x}\refl{f(x)})$, there exists
  %
  \begin{equation*}
    k:\prd{f,g:\prd{a:A} B(a)}{h:f\htpy g} D(f,g,h)
  \end{equation*}
  %
  such that $k(f,f,\lam{x}\refl{f(x)}) = d(f)$ for all $f$.
\end{cor}

\sectionNotes

Inductive definitions have a long pedigree in mathematics, arguably going back at least to Frege and Peano's axioms for the natural numbers.\index{Frege}\index{Peano} %
More general ``inductive predicates'' are not uncommon, but in set theoretic foundations they are usually constructed explicitly, either as an intersection of an appropriate class of subsets or using transfinite iteration along the ordinals, rather than regarded as a basic notion.

In type theory, particular cases of inductive definitions date back to Martin-L\"of's original papers: \cite{martin-lof-hauptsatz} presents a general notion of inductively defined predicates and relations; the notion of inductive type was present (but only with instances, not as a general notion) in Martin-L\"of's first papers in type theory \cite{Martin-Lof-1973};
and then as a general notion with $\w$-types in \cite{Martin-Lof-1979}.\index{Martin-L\"of}%

A general notion of inductive type was introduced in 1985 by Constable and Mendler~\cite{DBLP:conf/lop/ConstableM85}.  A general schema for inductive types in intensional type theory was suggested in
\cite{PfenningPaulinMohring}.  Further developments included \cite{CoquandPaulin, Dybjer:1991}.

The notion of inductive-recursive definition appears in \cite{Dybjer:2000}. An important  type-theoretic notion is the notion of tree types (a general expression of the notion of Post system in type theory) which appears in \cite{PeterssonSynek}.

The universal property of the natural numbers as an initial object of the category of $\nat$-algebras is due to Lawvere \cite{lawvere:adjinfound}\index{Lawvere}.
This was later generalized to a description of $\w$-types as initial algebras for polynomial endofunctors by~\cite{mp:wftrees}.\index{endofunctor!algebra for}
The coherently homotopy-theoretic equivalence between such universal properties and the corresponding induction principles (\cref{sec:initial-alg,sec:htpy-inductive}) is due to~\cite{ags:it-hott}.

For actual constructions of inductive types in homotopy-theoretic semantics of type theory, see~\cite{klv:ssetmodel,mvdb:wtypes,ls:hits}.

\sectionExercises

\begin{ex}\label{ex:ind-lst}
  Derive the induction principle for the type $\lst{A}$ of lists from its definition as an inductive type in \cref{sec:bool-nat}.\index{type!of lists}
\end{ex}

\begin{ex}\label{ex:same-recurrence-not-defeq}
  Construct two functions on natural numbers which satisfy the same recurrence\index{recurrence} $(e_z, e_s)$ judgmentally, but are not judgmentally equal.
\end{ex}

\begin{ex}\label{ex:one-function-two-recurrences}
  Construct two different recurrences $(e_z,e_s)$ on the same type $E$ which are both satisfied judgmentally by the same function $f:\nat\to E$.
\end{ex}

\begin{ex}\label{ex:bool}
  Show that for any type family $E : \bool \to \type$, the induction operator
  \[ \ind{\bool}(E) : \big(E(\bfalse) \times E(\btrue)\big) \to \prd{b : \bool} E(b) \]
  is an equivalence.
\end{ex}

\begin{ex}\label{ex:ind-nat-not-equiv}
  Show that the analogous statement to \cref{ex:bool} for $\nat$ fails.
\end{ex}

\begin{ex}\label{ex:no-dep-uniqueness-failure}
  Show that if we assume simple instead of dependent elimination for $\w$-types, the uniqueness property (analogue of \cref{thm:w-uniq}) fails to hold.
  That is, exhibit a type satisfying the recursion principle of a $\w$-type, but for which functions are not determined uniquely by their recurrence\index{recurrence}.
\end{ex}

\begin{ex}\label{ex:loop}
  Suppose that in the ``inductive definition'' of the type $C$ at the beginning of \cref{sec:strictly-positive}, we replace the type \nat by \emptyt.
  Analogously to~\eqref{eq:fake-recursor}, we might consider a recursion principle for this type with hypothesis
  \[ h:(C\to\emptyt) \to (P\to\emptyt) \to P. \]
  Show that even without a computation rule, this recursion principle is inconsistent, i.e.\ it allows us to construct an element of \emptyt.
\end{ex}

\begin{ex}\label{ex:loop2}
  Consider now an ``inductive type'' $D$ with one constructor $\mathsf{scott}:(D\to D) \to D$.
  \index{Scott}%
  The second recursor for $C$ suggested in \cref{sec:strictly-positive} leads to the following recursor for $D$:
  \[ \rec{D} : \prd{P:\UU} ((D\to D) \to (D\to P)\to P) \to D \to P \]
  with computation rule $\rec{D}(P,h,\mathsf{scott}(\alpha)) \jdeq h(\alpha,(\lam{d} \rec{D}(P,h,\alpha(d))))$.
  Show that this also leads to a contradiction.
\end{ex}

\begin{ex}\label{ex:inductive-lawvere}
  Let $A$ be an arbitrary type and consider generally an ``inductive definition'' of a type $L_A$ with constructor $\mathsf{lawvere}:(L_A\to A) \to L_A$.
  The second recursor for $C$ suggested in \cref{sec:strictly-positive} leads to the following recursor for $L_A$:
  \[ \rec{L_A} : \prd{P:\UU} ((L_A\to A) \to P) \to L_A\to P \]
  with computation rule $\rec{L_A}(P,h,\mathsf{lawvere}(\alpha)) \jdeq h(\alpha)$.
  Using this, show that $A$ has the \define{fixed-point property}, i.e.\ for every function $f:A\to A$ there exists an $a:A$ such that $f(a)=a$.
  \index{Lawvere}%
  \index{fixed-point property}%
  In particular, $L_A$ is inconsistent if $A$ is a type without the fixed-point property, such as $\emptyt$, $\bool$, or $\nat$.
\end{ex}

\begin{ex}\label{ex:ilunit}
  Continuing from \cref{ex:inductive-lawvere}, consider $L_\unit$, which is not obviously inconsistent since $\unit$ does have the fixed-point property.
  Formulate an induction principle for $L_\unit$ and its computation rule, analogously to its recursor, and using this, prove that it is contractible.
\end{ex}

\begin{ex}\label{ex:empty-inductive-type}
In \cref{sec:bool-nat} we defined the type $\lst A$ of finite lists of elements of some type $A$.
Consider a similar inductive definition of a type $\lost A$ whose only constructor is
\[ \cons: A \to \lost A \to \lost A. \]
Show that $\lost A$ is equivalent to $\emptyt$.
\end{ex}

\begin{ex}\label{ex:Wprop}
  Suppose $A$ is a mere proposition, and $B:A\to \UU$.
  \begin{enumerate}
  \item Show that $\wtype{a:A} B(a)$ is a mere proposition.
  \item Show that $\wtype{a:A} B(a)$ is equivalent to $\sm{a:A} \neg B(a)$.
  \item Without using $\wtype{a:A} B(a)$, show that $\sm{a:A} \neg B(a)$ is a homotopy $\w$-type $\wtypeh{a:A} B(a)$ in the sense of \cref{sec:htpy-inductive}.
  \end{enumerate}
\end{ex}

\begin{ex}\label{ex:Wbounds}
  Let $A:\UU$ and $B:A\to \UU$.
  \begin{enumerate}
  \item Show that $\Parens{\sm{a:A} \neg B(a)} \to \Parens{\wtype{a:A} B(a)}$.
  \item Show that $\Parens{\wtype{a:A} B(a)} \to \Parens{\neg \prd{a:A} B(a)}$.
  \end{enumerate}
\end{ex}

\begin{ex}\label{ex:Wdec}
  Let $A:\UU$ and suppose that $B:A\to \UU$ is decidable, i.e.\ $\prd{a:A} (B(a)+\neg B(a))$ (see \cref{defn:decidable-equality}).
  Show that $\Parens{\wtype{a:A} B(a)} \to \Parens{\sm{a:A} \neg B(a)}$.
\end{ex}

\begin{ex}\label{ex:Wbounds-loose}
  Show that the following are logically equivalent.
  \begin{enumerate}
  \item $\Parens{\wtype{a:A} B(a)} \to \Brck{\sm{a:A} \neg B(a)}$ for any $A:\set$ and $B:A\to \prop$.\label{item:Wbounds-loose-Sigma}
  \item $\Parens{\neg \prd{a:A} B(a)} \to \Brck{\wtype{a:A} B(a)}$ for any $A:\set$ and $B:A\to \prop$.\label{item:Wbounds-loose-Pi}
  \item The law of excluded middle (as in \cref{sec:intuitionism}).
  \end{enumerate}
  Similarly, using \cref{thm:not-lem}, show that it is inconsistent to assume that either implication in~\ref{item:Wbounds-loose-Sigma} or~\ref{item:Wbounds-loose-Pi} holds for all $A:\UU$ and $B:A\to \UU$.
\end{ex}

\begin{ex}\label{ex:Wimpred}
  For $A:\UU$ and $B:A\to \UU$, define
  \[ W'_{A,B} \defeq \prd{R:\UU} \Parens{\prd{a:A} (B(a) \to R) \to R} \to R \]
  $W'_{A,B}$ is called the \define{impredicative encoding of $\wtype{a:A} B(a)$}.
  \index{impredicative!encoding of a W-type@encoding of a $\w$-type}%
  \index{W-type@$\w$-type!impredicative encoding of}%
  Note that unlike $\wtype{a:A} B(a)$, it lives in a higher universe than $A$ and $B$.
  \begin{enumerate}
  \item Show that $W'_{A,B}$ is logically equivalent (as defined in \cref{sec:pat}) to $\wtype{a:A} B(a)$.
  \item Show that $W'_{A,B}$ implies $\neg\neg \sm{a:A} \neg B(a)$.
  \item Without using $\wtype{a:A} B(a)$, show that $W'_{A,B}$ satisfies the same \emph{recursion} principle as $\wtype{a:A} B(a)$ for defining functions into types in the universe $\UU$ (to which it itself does not belong).
  \item Using \LEM, give an example of an $A:\UU$ and a $B:A\to \UU$ such that $W'_{A,B}$ is not equivalent to $\wtype{a:A} B(a)$.
  \end{enumerate}
\end{ex}

\begin{ex}\label{ex:no-nullary-constructor}
  Show that for any $A:\UU$ and $B:A\to\UU$, we have
  \[ \eqv{\neg\Parens{\wtype{a:A} B(a)}}{\neg\Parens{\sm{a:A} \neg B(a)}}. \]
  In other words, $\wtype{a:A} B(a)$ is empty if and only if it has no nullary constructor.
  (Compare to \cref{ex:empty-inductive-type}.)
\end{ex}

% Local Variables:
% TeX-master: "hott-online"
% End:
